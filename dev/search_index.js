var documenterSearchIndex = {"docs":
[{"location":"types/","page":"Types","title":"Types","text":"CurrentModule = HighFrequencyCovariance","category":"page"},{"location":"types/#Structs","page":"Types","title":"Structs","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"Pages = [\"types.md\"]","category":"page"},{"location":"types/","page":"Types","title":"Types","text":"The SortedDataFrame struct wraps a DataFrame (from the DataFrames package). In the constructor function for the DataFrame we presort the data and create a mapping Dict so that it is fast to subset the DataFrame by the group.","category":"page"},{"location":"types/","page":"Types","title":"Types","text":"The CovarianceMatrix mutable struct stores three elements. A Hermitian correlation matrix, a vector of volatilities and a vector of labels. The order of the labels matches the order of the assets in the volatility vector and correlation matrix.","category":"page"},{"location":"types/#Structs-specification","page":"Types","title":"Structs specification","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"SortedDataFrame\nCovarianceMatrix","category":"page"},{"location":"types/#HighFrequencyCovariance.SortedDataFrame","page":"Types","title":"HighFrequencyCovariance.SortedDataFrame","text":"SortedDataFrame(df::DataFrame, time::Symbol = :Time, grouping::Symbol = :Name, value::Symbol = :Value)\n\nThis struct wraps a DataFrame. In the constructor function for the dataframe we presort the data and create a mapping dict so that it is fast to subset the DataFrame by the group.\n\nFor the constructor pass in the dataframe, name of time column, name of grouping  column and name of value column to the constructor.\n\nInputs\n\ndf - The tick data\ntime - The column of the data representing time.\ngrouping - The column of the data representing the asset name\nvalue - The column of the data representing price/logprice/etc.\ntime_period_per_unit - The period that one unit (in the time column) corresponds to.\n\nReturns\n\nA SortedDataFrame.\n\n\n\n\n\n","category":"type"},{"location":"types/#HighFrequencyCovariance.CovarianceMatrix","page":"Types","title":"HighFrequencyCovariance.CovarianceMatrix","text":"CovarianceMatrix(correlation::Hermitian{R}, volatility::Vector{R},\n                 labels::Vector{Symbol}) where R<:Real\n\nThis Struct stores three elements. A Hermitian correlation matrix, a vector of volatilities and a vector of labels. The order of the labels matches the order of the assets in the volatility vector and correlation matrix. The default constructor is used.\n\nInputs\n\ncorrelation - A Hermitian correlation matrix.\nvolatility - Volatilities for each asset.\nlabels - The labels for the correlation and volatility members. The n'th entry of the labels vector should contain the name of the asset that has its volatility in the n'th entry of the volatility member and its correlations in the n'th row/column of the correlation member.\ntime_period_per_unit - The period that one unit of volatility corresponds to.\n\nReturns\n\nA CovarianceMatrix.\n\n\n\n\n\n","category":"type"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"CurrentModule = HighFrequencyCovariance","category":"page"},{"location":"functions/#Estimation-Functions","page":"Estimation Functions","title":"Estimation Functions","text":"","category":"section"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"Pages = [\"functions.md\"]","category":"page"},{"location":"functions/#Estimating-Volatility","page":"Estimation Functions","title":"Estimating Volatility","text":"","category":"section"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"The estimate_volatility function is the main volatility estimation function. Either of the two estimation methods can be called by specifying :simple_volatility or :two_scales_volatility as the method argument in the estimate_volatility function. Alternatively the simple_volatility or two_scales_volatility functions can be called directly.","category":"page"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"The simple_volatility returns a  Dict with the estimated volatility for each asset. The two_scales_volatility function on the other hand returns a tuple with a Dict of estimated volatilities in the first position and a Dict of estimated microstructure noise variances in the second. For uniformity of output the estimate_volatility returns a Dict with the estimated volatility for each asset regardless of what method is chosen.","category":"page"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"If a user wants to calculate both volatilities and microstructure noises then they are advised to prefer the two_scales_volatility function over doing both estimate_volatility (with the :two_scale_covariance method argument) and the estimate_microstructure_noise function. While the results are the same doing the two function option means everything is calculated twice.","category":"page"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"    estimate_volatility\n    simple_volatility\n    two_scales_volatility","category":"page"},{"location":"functions/#HighFrequencyCovariance.estimate_volatility","page":"Estimation Functions","title":"HighFrequencyCovariance.estimate_volatility","text":"estimate_volatility(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts),\n                    method::Symbol = :two_scales_volatility;\n                    time_grid::Union{Missing,Dict} = missing ,\n                    fixed_spacing::Union{Missing,Dict,<:Real} = missing,\n                    use_all_obs::Bool = false, rough_guess_number_of_intervals::Integer = 5,\n                    num_grids::Real = default_num_grids(ts))\n\nThis is a convenience wrapper for the two volatility estimation techniques included in this package.\n\nGeneral Inputs\n\nts - The tick data.\nassets - What assets from ts that you want to estimate the covariance for.\nmethod - The method can be :simple_volatility (for the simple volatility method) or :two_scales_volatility (for the two scales volatility method)\n\nInputs only used in :simple_volatility method.\n\ntime_grid - The grid with which to calculate returns. If missing one is generated with a fixed spacing (if that is provided) or a default spacing.\nfixed_spacing - A spacing used to calculate a time grid. Not used if a time_grid is input or if use_all_obs = true.\nuse_all_obs - Use all observations to estimate volatilities. Not used if a time_grid is provided.\nrough_guess_number_of_intervals - A rough number of intervals to calculate a default spacing. Not used if a time_grid or fixed_spacing is provided or if use_all_obs = true.\n\nInputs only used in :two_scales_volatility method.\n\nnum_grids - Number of grids used in order in two scales estimation.\n\nReturns\n\nA Dict with estimated volatilities for each asset.\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.simple_volatility","page":"Estimation Functions","title":"HighFrequencyCovariance.simple_volatility","text":"simple_volatility(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts);\n                  time_grid::Union{Missing,Dict} = missing , fixed_spacing::Union{Missing,Dict,<:Real} = missing,\n                  use_all_obs::Bool = false, rough_guess_number_of_intervals::Integer = 5)\n\nCalculates volatility with the simple method.\n\nInputs\n\nts - The tick data.\nassets - The assets you want to estimate volatilities for.\ntime_grid - The grid with which to calculate returns. If missing one is generated with a fixed spacing (if that is provided) or a default spacing.\nfixed_spacing - A spacing used to calculate a time grid. Not used if a time_grid is input or if use_all_obs = true.\nuse_all_obs - Use all observations to estimate volatilities. Not used if a time_grid is provided.\nrough_guess_number_of_intervals - A rough number of intervals to calculate a default spacing. Not used if a time_grid or fixed_spacing is provided or if use_all_obs = true.\n\nReturns\n\nA Dict with an estimated volatility for each asset.\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.two_scales_volatility","page":"Estimation Functions","title":"HighFrequencyCovariance.two_scales_volatility","text":"two_scales_volatility(vals::Vector, times::Vector, asset::Symbol, num_grids::Real)\n\nCalculates volatility with the two scales method of Zhang, Mykland, Ait-Sahalia 2005. The amount of time for the grid spacing is by default this is a tenth of the total duration by default. If this doesn't make sense for your use of it then choose a spacing at which you expect the effect of microstructure noise will be small.\n\nInputs\n\nvals - The prices at each instant in time.\ntimes - The times corresponding to each element in vals.\nasset - The name of the asset.\nnum_grids - Number of grids used in order in two scales estimation.\n\nReturns\n\nA scalar for the estimated volatility of the asset.\nA scalar for the estimated microstructure noise variance.\n\ntwo_scales_volatility(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts);\n                      num_grids::Real = default_num_grids(ts))\n\nCalculates volatility with the two scales method of Zhang, Mykland, Ait-Sahalia 2005. The amount of time for the grid spacing is by default this is a tenth of the total duration by default. If this doesn't make sense for your use of it then choose a spacing at which you expect the effect of microstructure noise will be small.\n\nInputs\n\nts - The tick data.\nassets - The assets you want to estimate volatilities for.\nnum_grids - Number of grids used in order in two scales estimation.\n\nReturns\n\nA  Dict with estimated volatilities for each asset.\nA  Dict with estimated microstructure noise variances for each asset.\n\nReferences\n\nZhang L, Mykland PA, Aït-Sahalia Y (2005). \"A Tale of Two Time Scales: Determining Integrated Volatility with Noisy High-Frequency Data.\" Journal of the American Statistical Association, 100(472), 1394–1411. ISSN 01621459. doi:10.1198/016214505000000169.\n\n\n\n\n\n","category":"function"},{"location":"functions/#Estimating-Microstructure-Noise","page":"Estimation Functions","title":"Estimating Microstructure Noise","text":"","category":"section"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"There is one function that returns a Dict of microstructure noise estimates for each asset. These estimates come from the two_scales_volatility method and are identical to what you get if you examine the second element of the tuple that that function outputs.","category":"page"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"    estimate_microstructure_noise","category":"page"},{"location":"functions/#HighFrequencyCovariance.estimate_microstructure_noise","page":"Estimation Functions","title":"HighFrequencyCovariance.estimate_microstructure_noise","text":"estimate_microstructure_noise(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts);\n                              num_grids::Real = default_num_grids(ts))\n\nThis estimates microstructure noise with the twoscalesvolatility method.\n\nInputs\n\nts - The tick data.\nassets - What assets from ts that you want to estimate the covariance for.\nnum_grids - Number of grids used in order in two scales estimation.\n\nReturns\n\nA Dict with estimated microstructure noise variances for each asset.\n\n\n\n\n\n","category":"function"},{"location":"functions/#Estimating-Covariance-Matrices","page":"Estimation Functions","title":"Estimating Covariance Matrices","text":"","category":"section"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"The estimate_covariance is the main method for estimating a CovarianceMatrix. Five possible methods can be input to this function (or the functions for each method can alternatively be called directly).","category":"page"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"All covariance estimation functions take in a SortedDataFrame and (optionally) a vector of symbol names representing assets and (optionally) a specified regularisation method. If the vector of symbol names for assets in input then the CovarianceMatrix will only include those input assets and assets will be in the order specified in the vector.","category":"page"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"If the regularisation method is specified then this will be used in regularising the resulting matrix. This can alternatively be missing in which case no regularisation will be done. By default the nearest_psd_matrix will be used for every method except the two_scales_covariance method and this regularisation is done on the estimated covariance matrix before its correlation matrix and volatilities are split up and placed in a CovarianceMatrix struct. For the two_scales_covariance method the correlation matrix is estimated directly and regularisation is applied to this correlation matrix. Hence the nearest_correlation_matrix is the default.","category":"page"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"Note that some combinations of estimation technique and regularisation technique will not work. For instance nearest_correlation_matrix would not be good to apply in the case of the preaveraged_covariance method as it would attempt to make a covariance matrix into a correlation matrix with a unit diagonal. In addition if the estimated matrix is very non-psd then heavy regularisation might be required. This may have bad results. In these cases it may be useful to turn off regularisation in the estimation function and instead apply regularisation to the CovarianceMatrix struct.","category":"page"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"      estimate_covariance\n      simple_covariance\n      bnhls_covariance\n      spectral_covariance\n      preaveraged_covariance\n      two_scales_covariance","category":"page"},{"location":"functions/#HighFrequencyCovariance.estimate_covariance","page":"Estimation Functions","title":"HighFrequencyCovariance.estimate_covariance","text":"estimate_covariance(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts),\n                    method::Symbol = :preaveraged_covariance;\n                    regularisation::Union{Missing,Symbol} = :default, regularisation_params::Dict = Dict(),\n                    only_regulise_if_not_PSD::Bool = false,\n                    time_grid::Union{Missing,Vector} = missing,\n                    fixed_spacing::Union{Missing,<:Real} = missing, refresh_times::Bool = false,\n                    rough_guess_number_of_intervals::Integer = 5,\n                    kernel::HFC_Kernel{<:Real} = parzen,\n                    H::Real = kernel.c_star * ( mean(map(a -> length(ts.groupingrows[a]), assets))   )^0.6,\n                    m::Integer = 2, # BNHLS parameters, numJ::Integer = 100, num_blocks::Integer = 10,\n                    block_width::Real = (maximum(ts.df[:,ts.time]) - minimum(ts.df[:,ts.time])) / num_blocks,\n                    microstructure_noise_var::Dict{Symbol,<:Real} = two_scales_volatility(ts, assets)[2],\n                    theta::Real = 0.15, g::NamedTuple = g,\n                    equalweight::Bool = false, num_grids::Real = default_num_grids(ts))\n\nThis is a convenience wrapper for the regularisation techniques.\n\nGeneral Inputs\n\nts - The tick data.\nassets - What assets from ts that you want to estimate the covariance for.\nmethod  - The method you want to use. This can be :simple_covariance, :bnhls_covariance, :spectral_covariance, :preaveraged_covariance or :two_scales_covariance.\nregularisation - The regularisation method to use. This can be :identity_regularisation, :eigenvalue_clean, :nearest_correlation_matrix or :nearest_psd_matrix. You can also choose :covariance_default (which is :nearest_psd_matrix) or  :correlation_default (which is :nearest_correlation_matrix). If missing then the default regularisation method for your chosen covariance estimation method will be used.\nregularisation_params - Keyword arguments that will be used by your chosen regularisation method.\nonly_regulise_if_not_PSD - Should the resultant matrix only be regularised if it is not psd.\n\nInputs only used in :simple_covariance method.\n\ntime_grid - The grid with which to calculate returns (:simple_covariance method only).\nfixed_spacing - A spacing used to calculate a time grid. Not used if refresh_times=true (:simple_covariance method only).\nrefresh_times - Should refresh times be used to estimate covariance (:simple_covariance method only).\nrough_guess_number_of_intervals - A rough number of intervals to calculate a default spacing. Not used if a time_grid or fixed_spacing is provided or if refresh_times=true (:simple_covariance method only).\n\nInputs only used in :bnhls_covariance method.\n\nkernel - The kernel used. See the bnhls paper for details. (:bnhls_covariance method only)\nH - The number of lags/leads used in estimation. See the bnhls paper for details. (:bnhls_covariance method only)\nm - The number of end returns to average. (:bnhls_covariance method only)\n\nInputs only used in :spectral_covariance method.\n\nnumJ - The number of J values. See the paper for details (:spectral_covariance method only).\nnum_blocks - The number of blocks to split the time frame into. See the preaveraging paper for details (:spectral_covariance method only).\nblock_width - The width of each block to split the time frame into (:spectral_covariance method only).\nmicrostructure_noise_var - Estimates of microstructure noise variance for each asset (:spectral_covariance method only).\n\nInputs only used in :preaveraged_covariance method.\n\ntheta - A theta value. See paper for details (:preaveraged_covariance method only).\ng - A tuple containing a preaveraging method (with name \"f\") and a ψ value. See paper for details (:preaveraged_covariance method only).\n\nInputs only used in :two_scales_covariance method.\n\nequalweight - Should we use equal weight for the two different linear combinations of assets. If false then an optimal weight is calculated (from volatilities) (:two_scales_covariance method only).\nnum_grids - Number of grids used in order in two scales estimation (:two_scales_covariance method only).\n\nReturns\n\nA CovarianceMatrix\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.simple_covariance","page":"Estimation Functions","title":"HighFrequencyCovariance.simple_covariance","text":"simple_covariance(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts);\n                  regularisation::Union{Missing,Symbol} = :covariance_default,\n                  regularisation_params::Dict = Dict(), only_regulise_if_not_PSD::Bool = false,\n                  time_grid::Union{Missing,Vector} = missing, fixed_spacing::Union{Missing,<:Real} = missing,\n                  refresh_times::Bool = false, rough_guess_number_of_intervals::Integer = 5)\n\nEstimation of the covariance matrix in the standard textbook way.\n\nInputs\n\nts - The tick data.\nassets - The assets you want to estimate volatilities for.\nregularisation - A symbol representing what regularisation technique should be used. If missing no regularisation is performed.\nregularisation_params - keyword arguments to be consumed in the regularisation algorithm.\nonly_regulise_if_not_PSD - Should regularisation only be attempted if the matrix is not psd already.\ntime_grid - The grid with which to calculate returns.\nfixed_spacing - A spacing used to calculate a time grid. Not used if refresh_times=true.\nrefresh_times - Should refresh times be used to estimate covariance.\nrough_guess_number_of_intervals - A rough number of intervals to calculate a default spacing. Not used if a time_grid or fixed_spacing is provided or if refresh_times=true.\n\nReturns\n\nA CovarianceMatrix.\n\nReferences\n\nhttps://en.wikipedia.org/wiki/Samplemeanand_covariance\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.bnhls_covariance","page":"Estimation Functions","title":"HighFrequencyCovariance.bnhls_covariance","text":"bnhls_covariance(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts);\n                 regularisation::Union{Missing,Symbol} = :covariance_default,\n                 regularisation_params::Dict = Dict(), only_regulise_if_not_PSD::Bool = false,\n                 kernel::HFC_Kernel{<:Real} = parzen,\n                 H::Real = kernel.c_star * ( mean(map(a -> length(ts.groupingrows[a]), assets))   )^0.6,\n                 m::Integer = 2)\n\nThis calculates covariance with the Multivariate realised kernel oof BNHLS(2011).\n\nInputs\n\nts - The tick data.\nassets - The assets you want to estimate volatilities for.\nregularisation - A symbol representing what regularisation technique should be used. If missing no regularisation is performed.\nregularisation_params - keyword arguments to be consumed in the regularisation algorithm.\nonly_regulise_if_not_PSD - Should regularisation only be attempted if the matrix is not psd already.\nkernel - The kernel used. See the paper for details.\nH - The number of lags/leads used in estimation. See the paper for details.\nm - The number of end returns to average.\n\nReturns\n\nA CovarianceMatrix.\n\nReferences\n\nBarndorff-Nielsen, O., Hansen, P.R., Lunde, A., Shephard, N. 2011. - The whole paper but particularly 2.2, 2.3 here. Kernels are in table 1. choices of H are discussed in section 3.4 of the paper.\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.spectral_covariance","page":"Estimation Functions","title":"HighFrequencyCovariance.spectral_covariance","text":"spectral_covariance(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts);\n                    regularisation::Union{Missing,Symbol} = :covariance_default,\n                    regularisation_params::Dict = Dict(), only_regulise_if_not_PSD::Bool = false,\n                    numJ::Integer = 100, num_blocks::Integer = 10,\n                    block_width::Real = (maximum(ts.df[:,ts.time]) - minimum(ts.df[:,ts.time])) / num_blocks,\n                    microstructure_noise_var::Dict{Symbol,<:Real} = two_scales_volatility(ts, assets)[2])\n\nEstimation of a CovarianceMatrix using the spectral covariance method.\n\nInputs\n\nts - The tick data.\nassets - The assets you want to estimate volatilities for.\nregularisation - A symbol representing what regularisation technique should be used. If missing no regularisation is performed.\nregularisation_params - keyword arguments to be consumed in the regularisation algorithm.\nonly_regulise_if_not_PSD - Should regularisation only be attempted if the matrix is not psd already.\nnumJ - The number of J values. See the paper for details.\nnum_blocks - The number of blocks to split the time frame into. See the paper for details.\nblock_width - The width of each block to split the time frame into.\nmicrostructure_noise_var - Estimates of microstructure noise variance for each asset.\n\nReturns\n\nA CovarianceMatrix.\n\nReferences\n\nBibinger M, Hautsch N, Malec P, Reiss M (2014). “Estimating the quadratic covariation matrix from noisy observations: Local method of moments and efficiency.” The Annals of Statistics, 42(4), 1312–1346. doi:10.1214/14-AOS1224.\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.preaveraged_covariance","page":"Estimation Functions","title":"HighFrequencyCovariance.preaveraged_covariance","text":"preaveraged_covariance(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts);\n                       regularisation::Union{Missing,Symbol} = :covariance_default,\n                       regularisation_params::Dict = Dict(), only_regulise_if_not_PSD::Bool = false,\n                       theta::Real = 0.15, g::NamedTuple = g)\n\nEstimation of the CovarianceMatrix using preaveraging method.\n\nInputs\n\nts - The tick data.\nassets - The assets you want to estimate volatilities for.\nregularisation - A symbol representing what regularisation technique should be used. If missing no regularisation is performed.\nregularisation_params - keyword arguments to be consumed in the regularisation algorithm.\nonly_regulise_if_not_PSD - Should regularisation only be attempted if the matrix is not psd already.\ntheta - A theta value. See paper for details.\ng - A tuple containing a preaveraging method (with name \"f\") and a ψ value. See paper for details.\n\nReturns\n\nA CovarianceMatrix.\n\nReferences\n\nChristensen K, Podolskij M, Vetter M (2013). “On covariation estimation for multivariate continuous Itô semimartingales with noise in non-synchronous observation schemes.” Journal of Multivariate Analysis, 120, 59–84. doi:10.1016/j.jmva.2013.05.002.\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.two_scales_covariance","page":"Estimation Functions","title":"HighFrequencyCovariance.two_scales_covariance","text":"two_scales_covariance(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts);\n                      regularisation::Union{Missing,Symbol} = :correlation_default,\n                      regularisation_params::Dict = Dict(), only_regulise_if_not_PSD::Bool = false,\n                      equalweight::Bool = false, num_grids::Real = default_num_grids(ts))\n\nEstimation of a CovarianceMatrix using the two scale covariance method.\n\nInputs\n\nts - The tick data.\nassets - The assets you want to estimate volatilities for.\nregularisation - A symbol representing what regularisation technique should be used. If missing no regularisation is performed.\nregularisation_params - keyword arguments to be consumed in the regularisation algorithm.\nonly_regulise_if_not_PSD - Should regularisation only be attempted if the matrix is not psd already.\nequalweight - Should we use equal weight for the two different linear combinations of assets. If false then an optimal weight is calculated (from volatilities).\nnum_grids - Number of grids used in order in two scales estimation.\n\nReturns\n\nA CovarianceMatrix.\n\n\n\n\n\n","category":"function"},{"location":"functions/#Regularisation-of-Covariance-Matrices","page":"Estimation Functions","title":"Regularisation of Covariance Matrices","text":"","category":"section"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"The main function for regularisation is the regularise function. In addition four methods are implemented for regularising matrices can be used directly or through the regularise function. All of these functions can be applied to either a Hermitian matrix or to a CovarianceMatrix struct.","category":"page"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"If these functions are applied to a Hermitian then regularisation is applied and a regularised Hermitian is returned.","category":"page"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"If these functions are applied to a CovarianceMatrix struct.","category":"page"},{"location":"functions/","page":"Estimation Functions","title":"Estimation Functions","text":"    regularise\n    identity_regularisation\n    eigenvalue_clean\n    nearest_psd_matrix\n    nearest_correlation_matrix","category":"page"},{"location":"functions/#HighFrequencyCovariance.regularise","page":"Estimation Functions","title":"HighFrequencyCovariance.regularise","text":"regularise(mat::Hermitian, ts::SortedDataFrame,  mat_labels::Vector, method::Symbol = :correlation_default;\n           spacing::Union{Missing,<:Real} = missing,\n           weighting_matrix = Diagonal(eltype(mat).(I(size(mat)[1]))),\n           doDykstra = true, stop_at_first_correlation_matrix = true, max_iterates = 1000)\n\nThis is a convenience wrapper for the regularisation techniques.\n\nGeneral Inputs\n\nmat - The matrix you want to regularise.\nts - The tick data.\nmat_labels - The name of the assets for each row/column of the matrix.\nmethod  - The method you want to use. This can be :identity_regularisation, :eigenvalue_clean, :nearest_correlation_matrix or :nearest_psd_matrix. You can also choose :covariance_default (which is :nearest_psd_matrix) or  :correlation_default (which is :nearest_correlation_matrix).\n\nInputs only used in :identity_regularisation method.\n\nspacing - The interval spacing used in choosing an identity weight (identity_regularisation method only).\n\nInputs only used in :nearest_correlation_matrix method.\n\nweighting_matrix - The weighting matrix used to calculate the nearest psd matrix (:nearest_correlation_matrix method only).\ndoDykstra - Should a Dykstra correction be applied (:nearest_correlation_matrix method only).\nstop_at_first_correlation_matrix - Should we stop at first valid correlation matrix (:nearest_correlation_matrix method only).\nmax_iterates - Maximum number of iterates (:nearest_correlation_matrix method only).\n\nReturns\n\nA Hermitian\n\nregularise(covariance_matrix::CovarianceMatrix, ts::SortedDataFrame, method::Symbol = :nearest_correlation_matrix;\n           apply_to_covariance::Bool = true,\n           spacing::Union{Missing,<:Real} = missing,\n           weighting_matrix = Diagonal(eltype(covariance_matrix.correlation).(I(size(covariance_matrix.correlation)[1]))),\n           doDykstra = true, stop_at_first_correlation_matrix = true, max_iterates = 1000)\n\nThis is a convenience wrapper for the regularisation techniques.\n\nGeneral Inputs\n\ncovariance_matrix - The matrix you want to regularise.\nts - The tick data.\nmethod  - The method you want to use. This can be :identity_regularisation, :eigenvalue_clean, :nearest_correlation_matrix or :nearest_psd_matrix. You can also choose :covariance_default (which is :nearest_psd_matrix) or  :correlation_default (which is :nearest_correlation_matrix).\napply_to_covariance - Should regularisation be applied to the covariance matrix. If false it is applied to the correlation matrix.\n\nInputs only used in :identity_regularisation method.\n\nspacing - The interval spacing used in choosing an identity weight (identity_regularisation method only).\n\nInputs only used in :nearest_correlation_matrix method.\n\nweighting_matrix - The weighting matrix used to calculate the nearest psd matrix (:nearest_correlation_matrix method only).\ndoDykstra - Should a Dykstra correction be applied (:nearest_correlation_matrix method only).\nstop_at_first_correlation_matrix - Should we stop at first valid correlation matrix (:nearest_correlation_matrix method only).\nmax_iterates - Maximum number of iterates (:nearest_correlation_matrix method only).\n\nReturns\n\nA CovarianceMatrix\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.identity_regularisation","page":"Estimation Functions","title":"HighFrequencyCovariance.identity_regularisation","text":"identity_regularisation(mat::Hermitian, identity_weight::Real)\n\nRegularisation of the correlation matrix by mixing with the identity matrix.\n\nInputs\n\nmat - A matrix to be regularised.\nidentity_weight - How much weight to give to the identity matrix. Should be between 0 and 1.\n\nReturns\n\nA Hermitian.\n\nidentity_regularisation(mat::Hermitian, asset_returns::DataFrame) where R<:Real\n\nRegularisation of the correlation matrix by mixing with the identity matrix as per Ledoit & Wolf 2003.\n\nInputs\n\nmat - A matrix to be regularised.\nts - Tick data.\n\nReturns\n\nA Hermitian.\n\nidentity_regularisation(mat::Hermitian, ts::SortedDataFrame,  mat_labels::Vector;\n                        spacing::Union{Missing,<:Real} = missing)\n\nRegularisation of the correlation matrix by mixing with the identity matrix as per Ledoit & Wolf 2003.\n\nInputs\n\nmat - A matrix to be regularised.\nts - Tick data.\nmat_labels - The labels for each asset in the matrix.\nspacing A spacing to use to estimate returns. This is used in determining the optimal weight to give to the identity matrix.\n\nReturns\n\nA Hermitian.\n\nidentity_regularisation(covariance_matrix::CovarianceMatrix, ts::SortedDataFrame;\n                        spacing::Union{Missing,<:Real} = missing, apply_to_covariance::Bool = true)\n\nRegularisation of the correlation matrix by mixing with the identity matrix as per Ledoit & Wolf 2003.\n\nInputs\n\ncovariance_matrix - The CovarianceMatrix to be regularised.\nts - Tick data.\nspacing A spacing to use to estimate returns. This is used in determining the optimal weight to give to the identity matrix.\napply_to_covariance Should regularisation be applied to the covariance matrix or the correlation matrix.\n\nReturns\n\nA CovarianceMatrix.\n\nidentity_regularisation(covariance_matrix::CovarianceMatrix, identity_weight::Real;\n                        apply_to_covariance = false)\n\nRegularisation of the correlation matrix by mixing with the identity matrix.\n\nInputs\n\ncovariance_matrix - The CovarianceMatrix to be regularised.\nidentity_weight - How much weight to give to the identity matrix. Should be between 0 and 1.\napply_to_covariance Should regularisation be applied to the covariance matrix or the correlation matrix.\n\nReturns\n\nA CovarianceMatrix.\n\nReferences\n\nLedoit, O. , Wolf, M. 2003. Improved Estimation of the Covariance Matrix of Stock Returns with an application to portfolio selection. Journal of empirical finance. 10. 603-621.\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.eigenvalue_clean","page":"Estimation Functions","title":"HighFrequencyCovariance.eigenvalue_clean","text":"eigenvalue_clean(eigenvalues::Vector{<:Real}, eigenvectors::Matrix{<:Real},\n                 eigenvalue_threshold::Real)\n\nThis takes the small eigenvalues (with values below eigenvaluethreshold). It sets them to the greater of their average or eigenvaluethreshold/(4*numberofsmall_eigens). Then the matrix is reconstructed and returned (as a Hermitian)\n\nInputs\n\neigenvalues - The eigenvalues of a matrix.\neigenvectors - The eigenvectors  of a matrix.\neigenvalue_threshold - The threshold for a eigenvalue to be altered.\n\nReturns\n\nA Hermitian.\n\neigenvalue_clean(mat::Hermitian, eigenvalue_threshold::Real)\n\nThis splits a matrix into its eigenvalues and eigenvectors. Then takes the small eigenvalues (with values below eigenvaluethreshold). It sets them to the greater of their average or eigenvaluethreshold/(4*numberofsmall_eigens). Then the matrix is reconstructed and returned (as a Hermitian)\n\nInputs\n\nmat - A matrix that you want to regularise with eigenvalue regularisation.\neigenvalue_threshold - The threshold for a eigenvalue to be altered.\n\nReturns\n\nA Hermitian.\n\neigenvalue_clean(mat::Hermitian, ts::SortedDataFrame)\n\nSimilarly to the above two methods these functions regularise a matrix by setting small eigenvalues to near zero. The method of Laloux, Cizeau, Bouchaud & Potters 2000 is used to choose a threshold.\n\nInputs\n\nmat - A matrix that you want to regularise with eigenvalue regularisation.\nts - The tick data.\n\nReturns\n\nA Hermitian.\n\neigenvalue_clean(covariance_matrix::CovarianceMatrix, ts::SortedDataFrame;\n                 apply_to_covariance::Bool = true)\n\nInputs\n\nmat - A matrix that you want to regularise with eigenvalue regularisation.\nts - The tick data.\napply_to_covariance Should regularisation be applied to the covariance matrix or the correlation matrix.\n\nReturns\n\nA CovarianceMatrix.\n\nNote that if the input matrices include any NaN terms then regularisation is not possible. The matrix will be silently returned (as these NaNs will generally be from upstream problems so it is useful to return the matrix rather than throw at this point).As a result outputs should be checked.\n\nReferences\n\nLaloux, L., Cizeau, P., Bouchaud J. , Potters, M. 2000. \"Random matrix theory and financial correlations\" International Journal of Theoretical Applied FInance, 3, 391-397.\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.nearest_psd_matrix","page":"Estimation Functions","title":"HighFrequencyCovariance.nearest_psd_matrix","text":"nearest_psd_matrix(mat::Hermitian)\n\nThis function maps a Hermitian matrix to the nearest psd matrix. This uses the projecttoS method in Higham (2001; Theorem 3.2). No special weighting is applied in this case. Advanced users can use the project_to_S directly if they want to use weights in order to decide what the closest pds matrix.\n\nInputs\n\nmat - The matrix you want to map to a psd matrix\n\nResults\n\nA Hermitian\n\nnearest_psd_matrix(covariance_matrix::CovarianceMatrix;\n                   apply_to_covariance::Bool = true)\n\nThis function maps a Hermitian matrix to the nearest psd matrix. This uses the projecttoS method in Higham (2001; Theorem 3.2). No special weighting is applied in this case. Advanced users can use the project_to_S directly if they want to use weights in order to decide what the closest pds matrix.\n\nInputs\n\ncovariance_matrix - The matrix you want to map to a psd matrix\napply_to_covariance - Should regularisation be applied to the correlation or covariance matrix.\n\nResults\n\nA CovarianceMatrix\n\nnearest_psd_matrix(covariance_matrix::CovarianceMatrix, ts::SortedDataFrame;\n                   apply_to_covariance::Bool = true)\n\nThis function maps a Hermitian matrix to the nearest psd matrix. This uses the projecttoS method in Higham (2001; Theorem 3.2). No special weighting is applied in this case. Advanced users can use the project_to_S directly if they want to use weights in order to decide what the closest pds matrix.\n\nInputs\n\ncovariance_matrix - The matrix you want to map to a psd matrix\nts - The Tick data\napply_to_covariance - Should regularisation be applied to the correlation or covariance matrix.\n\nResults\n\nA CovarianceMatrix\n\nReferences\n\nHigham NJ (2002). \"Computing the nearest correlation matrix - a problem from finance.\" IMA Journal of Numerical Analysis, 22, 329–343. doi:10.1002/nla.258.\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.nearest_correlation_matrix","page":"Estimation Functions","title":"HighFrequencyCovariance.nearest_correlation_matrix","text":"nearest_correlation_matrix(mat::AbstractMatrix, weighting_matrix::Union{Diagonal,Hermitian} = Diagonal(Float64.(I(size(mat)[1])));\n                           doDykstra::Bool = true, stop_at_first_correlation_matrix::Bool = true, max_iterates::Integer = 1000)\n\nMaps a matrix to the nearest valid correlation matrix (pdf matrix with unit diagonal and all other entries below 1 in absolute value).\n\nInputs\n\nmat - A matrix you want to regularise.\nts - The tick data.\nweighting_matrix - The weighting matrix used to weight what the nearest valid correlation matrix is.\ndoDykstra - Should Dykstra correction be done.\nstop_at_first_correlation_matrix - Should we keep iterating until we have done all iterates or stop at the first valid correlation matrix.\nmax_iterates - The maximum number of iterates to do towards a valid correlation matrix.\n\nReturns\n\nA Matrix\nAn integer saying how many iterates were done\nA Symbol with a convergence message.\n\nnearest_correlation_matrix(covariance_matrix::CovarianceMatrix, ts::SortedDataFrame;\n                           weighting_matrix::Union{Diagonal,Hermitian} = Diagonal(eltype(covariance_matrix.correlation).(I(size(covariance_matrix.correlation)[1]))),\n                           doDykstra::Bool = true, stop_at_first_correlation_matrix::Bool = true,\n                           max_iterates::Integer = 1000)\n\nMaps a matrix to the nearest valid correlation matrix (pdf matrix with unit diagonal and all other entries below 1 in absolute value).\n\nInputs\n\ncovariance_matrix - The matrix you want to regularise.\nts - The tick data.\nweighting_matrix - The weighting matrix used to weight what the nearest valid correlation matrix is.\ndoDykstra - Should Dykstra correction be done.\nstop_at_first_correlation_matrix - Should we keep iterating until we have done all iterates or stop at the first valid correlation matrix.\nmax_iterates - The maximum number of iterates to do towards a valid correlation matrix.\n\nReturns\n\nA CovarianceMatrix\n\nnearest_correlation_matrix(covariance_matrix::CovarianceMatrix;\n                           weighting_matrix::Union{Diagonal,Hermitian} = Diagonal(eltype(covariance_matrix.correlation).(I(size(covariance_matrix.correlation)[1]))),\n                           doDykstra::Bool = true, stop_at_first_correlation_matrix::Bool = true,\n                           max_iterates::Integer = 1000)\n\nMaps a matrix to the nearest valid correlation matrix (pdf matrix with unit diagonal and all other entries below 1 in absolute value).\n\nInputs\n\ncovariance_matrix - The matrix you want to regularise.\nweighting_matrix - The weighting matrix used to weight what the nearest valid correlation matrix is.\ndoDykstra - Should Dykstra correction be done.\nstop_at_first_correlation_matrix - Should we keep iterating until we have done all iterates or stop at the first valid correlation matrix.\nmax_iterates - The maximum number of iterates to do towards a valid correlation matrix.\n\nReturns\n\nA CovarianceMatrix\n\nnearest_correlation_matrix(mat::Hermitian;\n                           weighting_matrix::Union{Diagonal,Hermitian} = Diagonal(eltype(mat).(I(size(mat)[1]))),\n                           doDykstra::Bool = true, stop_at_first_correlation_matrix::Bool = true,\n                           max_iterates::Integer = 1000)\n\nMaps a matrix to the nearest valid correlation matrix (pdf matrix with unit diagonal and all other entries below 1 in absolute value).\n\nInputs\n\nmat - The matrix you want to regularise.\nweighting_matrix - The weighting matrix used to weight what the nearest valid correlation matrix is.\ndoDykstra - Should Dykstra correction be done.\nstop_at_first_correlation_matrix - Should we keep iterating until we have done all iterates or stop at the first valid correlation matrix.\nmax_iterates - The maximum number of iterates to do towards a valid correlation matrix.\n\nReturns\n\nA Hermitian\n\nnearest_correlation_matrix(mat::Hermitian, ts::SortedDataFrame;\n                           weighting_matrix::Union{Diagonal,Hermitian} = Diagonal(eltype(mat).(I(size(mat)[1]))),\n                           doDykstra::Bool = true, stop_at_first_correlation_matrix::Bool = true,\n                           max_iterates::Integer = 1000)\n\nMaps a matrix to the nearest valid correlation matrix (pdf matrix with unit diagonal and all other entries below 1 in absolute value).\n\nInputs\n\ncovariance_matrix - The matrix you want to regularise.\nts - The tick data.\nweighting_matrix - The weighting matrix used to weight what the nearest valid correlation matrix is.\ndoDykstra - Should Dykstra correction be done.\nstop_at_first_correlation_matrix - Should we keep iterating until we have done all iterates or stop at the first valid correlation matrix.\nmax_iterates - The maximum number of iterates to do towards a valid correlation matrix.\n\nReturns\n\nA Hermitian\n\nReferences\n\nHigham NJ (2002). \"Computing the nearest correlation matrix - a problem from finance.\" IMA Journal of Numerical Analysis, 22, 329–343. doi:10.1002/nla.258.\n\n\n\n\n\n","category":"function"},{"location":"3_WritingCode/#Using-HighFrequencyCovariance","page":"Writing Code","title":"Using HighFrequencyCovariance","text":"","category":"section"},{"location":"3_WritingCode/#Loading-in-data","page":"Writing Code","title":"Loading in data","text":"","category":"section"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We first load our data into a DataFrame. As an example we have a DataFrame of price updates (like that in df in the below code block). Then we can put our data into a SortedDataFrame by putting the DataFrame and the names of the time, label and value columns into the constructor:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"using HighFrequencyCovariance\nusing DataFrames\n# Making example data\ndf = DataFrame(:stock => [:A,:B,:A,:A,:A,:B,:A,:B,:B], :time => [1,2,3,4,5,5,6,7,8],\n               :logprice => [1.01,2.0,1.011,1.02,1.011,2.2,1.0001,2.2,2.3])\n# Making a SortedDataFrame\nts = SortedDataFrame(df, :time, :stock, :logprice)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"In a real setting this is how we would turn our DataFrame of data into a SortedDataFrame.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"For the succeeding sections it is useful to get more realistic time series data. So we will generate some Monte Carlo data here using the generate_random_path function which generates a random correlation matrix, volatilities, price update times and microstructure noises and generates a SortedDataFrame from a random time series consistent with these.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"using HighFrequencyCovariance\nusing Random\ndims = 4\nticks = 10000\nts, true_covar, true_micro_noise, true_update_rates = generate_random_path(dims, ticks, twister = MersenneTwister(2))","category":"page"},{"location":"3_WritingCode/#Estimating-Volatility","page":"Writing Code","title":"Estimating Volatility","text":"","category":"section"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We can use the SortedDataFrame we have generated (in the ts variable) to estimate the volatility of each asset:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"assets         = get_assets(ts)\nsimple_vol     = estimate_volatility(ts, assets, :simple_volatility)\ntwo_scales_vol = estimate_volatility(ts, assets, :two_scales_volatility)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Now the true volatility is contained in true_covar.volatility. We can present these true volatilities alongside the two estimated volatilities","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"using DataFrames\ntrue_volatility = Dict{Symbol,Float64}(true_covar.labels .=> true_covar.volatility)\nsummary_frame = vcat(DataFrame.([true_volatility, simple_vol, two_scales_vol] )... )\nsummary_frame = hcat(DataFrame(Dict(:estimation => [\"True\", \"Simple\", \"2 Scales\"])), summary_frame)\nprint(summary_frame)\n# │ Row │ estimation │ asset_1   │ asset_2   │ asset_3    │ asset_4   │\n# │     │ String     │ Float64   │ Float64   │ Float64    │ Float64   │\n# ├─────┼────────────┼───────────┼───────────┼────────────┼───────────┤\n# │ 1   │ True       │ 0.0157077 │ 0.0137856 │ 0.00484516 │ 0.0142265 │\n# │ 2   │ Simple     │ 0.0178855 │ 0.0284619 │ 0.00502814 │ 0.0129842 │\n# │ 3   │ 2 Scales   │ 0.0173682 │ 0.0192129 │ 0.00605092 │ 0.0149015 │","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We can see that the accuracy of the simple method was particularly bad for asset_2.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"This is due to microstructure noise which we can estimate as:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"noise          = estimate_microstructure_noise(ts, assets)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"And tabling the estimated and true microstructure noise we can see that there was more microstructure noise for asset_2 relative to the other assets.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"using DataFrames\nsummary_frame = vcat(DataFrame.([true_micro_noise, noise] )... )\nsummary_frame = hcat(DataFrame(Dict(:estimation => [\"True\", \"2 Scales noise estimate\"])), summary_frame)\nprint(summary_frame)\n# 2×5 DataFrame\n# │ Row │ estimation              │ asset_1    │ asset_2    │ asset_3     │ asset_4     │\n# │     │ String                  │ Float64    │ Float64    │ Float64     │ Float64     │\n# ├─────┼─────────────────────────┼────────────┼────────────┼─────────────┼─────────────┤\n# │ 1   │ True                    │ 0.00216696 │ 0.0092135  │ 0.000226909 │ 0.000938589 │\n# │ 2   │ 2 Scales noise estimate │ 0.0021294  │ 0.00854816 │ 0.000226053 │ 0.000871175 │","category":"page"},{"location":"3_WritingCode/#Estimating-a-covariance-matrix","page":"Writing Code","title":"Estimating a covariance matrix","text":"","category":"section"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"As this is a Monte Carlo we already have the true CovarianceMatrix in the true_covar variable. As we don't have this in applied settings we will disregard this for now and try to estimate it using our generated tick data stored in the SortedDataFrame with name ts:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"assets              = get_assets(ts)\nsimple_estimate     = estimate_covariance(ts, assets, :simple_covariance)\nbnhls_estimate      = estimate_covariance(ts, assets, :bnhls_covariance)\nspectral_estimate   = estimate_covariance(ts, assets, :spectral_covariance)\npreav_estimate      = estimate_covariance(ts, assets, :preaveraged_covariance)\ntwo_scales_estimate = estimate_covariance(ts, assets, :two_scales_covariance)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We may alternatively use the functions corresponding to each method directly. This has the same result:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"bnhls_estimate2     = bnhls_covariance(ts, assets)\nspectral_estimate2  = spectral_covariance(ts, assets)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Now we may be particularly interested in one of the estimates, for instance the bnhls_estimate. We can first see if the correlation matrix it produces is valid (is positive semi-definite, has a unit diagonal and has all other entries below 1):","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"valid_correlation_matrix(bnhls_estimate)\n# true","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"and fortunately it is. We could also examine the others similarly and see that they all deliver valid correlation matrices. One thing we might try then is to average over all of the more advanced methods and use the result as our correlation matrix estimate. This is easy to achieve by using the combine_covariance_matrices function.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"matrices = [spectral_estimate, preav_estimate, two_scales_estimate, bnhls_estimate]\ncombined_estimate = combine_covariance_matrices(matrices)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Now we can compare how close each of the estimates is to the true correlation matrix. We can do this by examining the mean absolute difference between estimated correlations.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"calculate_mean_abs_distance(true_covar, combined_estimate)\n# (Correlation_error = 0.38723691161754376, Volatility_error = 0.002500211816000063)\ncalculate_mean_abs_distance(true_covar, simple_estimate)\n# (Correlation_error = 0.5321534542489482, Volatility_error = 0.010511960080115556)\ncalculate_mean_abs_distance(true_covar, bnhls_estimate)\n# (Correlation_error = 0.7422120933301078, Volatility_error = 0.006815323622470541)\ncalculate_mean_abs_distance(true_covar, spectral_estimate)\n# (Correlation_error = 0.5227424813357473, Volatility_error = 0.007669889385330695)\ncalculate_mean_abs_distance(true_covar, preav_estimate)\n# (Correlation_error = 0.1840684108352901, Volatility_error = 0.0022421828719004925)\ncalculate_mean_abs_distance(true_covar, two_scales_estimate)\n# (Correlation_error = 0.38238270061443486, Volatility_error = 0.0022421828719004925)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We can see that in this particular case the correlation matrix calculated with the preaveraging method performed the best.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Now examining the data we can see that we have some assets that trade more frequently than the others.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"ticks_per_asset(ts)\n# Dict{Symbol, Int64} with 4 entries:\n#   :asset_4 => 3454\n#   :asset_3 => 3242\n#   :asset_2 => 1340\n#   :asset_1 => 1964","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"While we have 3454 price updates for asset_4 we only have 1340 for asset_2. Potentially we could improve the bnhls estimate if we use a blocking and regularisation technique (Hautsch, Kyj and Oomen  2012).","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We can start this by first making a DataFrame detailing what assets should be in what block. We will generate a new block if the minimum number of ticks of a new block has 20% more ticks than the minimum of the previous:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"new_block_threshold = 1.2\nblocking_frame = put_assets_into_blocks_by_trading_frequency(\n                        ts, new_block_threshold, :bnhls_covariance)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"This blocking_frame is a regular DataFrame with six columns where each row represents a different estimation. The order of the rows is the order of estimations (so the results of later estimations may overwrite earlier ones). The first column is named :assets and has the type Set{Symbol} which represents the assets in each estimation. The second column contains a symbol representing the function that will be used in the estimation of that block. The third column has the name :optional_parameters and is of type NamedTuple that can provide optional parameters to the covariance function in the second column. Every covariance estimation has a function signature with two common arguments before the semicolon (For a SortedDataFrame and a vector of symbols representing what assets to use). There can also be a number of named optional arguments which can be sourced from a NamedTuple. The blockwise_estimation function then estimates a block with the line","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"blocking_frame[i,:f](ts, collect(blocking_frame[i,:assets]);\n                     blocking_frame[i,:optional_parameters]... )","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Thus a user can insert a named tuple containing whatever optional parameters are used by the function.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"The fourth, fifth and sixth columns contains the number of assets in the block, the mean number of ticks in the block and the mean time per tick. These do not do anything in the subsequent blockwise_estimation function but can be used to alter the DataFrame. Now in the current case we may decide to estimate the block containing all assets using the spectral_covariance method.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"one_asset_row = findall(blocking_frame[:,:number_of_assets] .== 4)\nblocking_frame[one_asset_row, :f] = :spectral_covariance","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We can now estimate the blockwise estimated CovarianceMatrix as:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"block_estimate = blockwise_estimation(ts, blocking_frame)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"After a blockwise estimation the result may often not be PSD. So we could regularise at this point:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"reg_block_estimate = regularise(block_estimate , ts, :nearest_correlation_matrix)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Finally we might seek to use one of our estimated CovarianceMatrixs to calculate an actual covariance matrix over some interval. This can be done with the code:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"covariance_interval = 1000\ncovar = covariance(combined_estimate, covariance_interval)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Note that the time units of the covariance_interval here should be the same units as the CovarianceMatrix struct's volatility which are the same units as the time dimension in the SortedDataFrame that is used to estimate the CovarianceMatrix.","category":"page"},{"location":"helper_functions/","page":"Helper Functions","title":"Helper Functions","text":"CurrentModule = HighFrequencyCovariance","category":"page"},{"location":"helper_functions/#Helper-Functions","page":"Helper Functions","title":"Helper Functions","text":"","category":"section"},{"location":"helper_functions/","page":"Helper Functions","title":"Helper Functions","text":"Pages = [\"helper_functions.md\"]","category":"page"},{"location":"helper_functions/#Working-with-SortedDataFrame-structs","page":"Helper Functions","title":"Working with SortedDataFrame structs","text":"","category":"section"},{"location":"helper_functions/","page":"Helper Functions","title":"Helper Functions","text":"    get_assets\n    ticks_per_asset\n    duration\n    subset_to_tick\n    subset_to_time","category":"page"},{"location":"helper_functions/#HighFrequencyCovariance.get_assets","page":"Helper Functions","title":"HighFrequencyCovariance.get_assets","text":"get_assets(ts::SortedDataFrame, obs_to_include::Integer = 10)\n\nThis returns a vector of all of the assets in the SortedDataFrame with at least some number of observations (10 by default).\n\nInputs\n\nts - The tick data.\nobs_to_include - An integer for the minimum number of ticks in ts needed for the function to include that asset.\n\nReturns\n\nA Vector{Symbol} with each asset.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.ticks_per_asset","page":"Helper Functions","title":"HighFrequencyCovariance.ticks_per_asset","text":"ticks_per_asset(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts))\n\nCount the number of observations for each asset.\n\nInputs\n\nts - The tick data\nassets - A vector with asset Symbols.\n\nReturns\n\nA Dict with the number of observations for each input asset.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.duration","page":"Helper Functions","title":"HighFrequencyCovariance.duration","text":"duration(ts::SortedDataFrame)\n\nThe time elapsed between the first and the last tick in a SortedDataFrame.\n\nInputs\n\nts - Tick data.\nin_dates_period - In Dates.Period format or just a number for the numeric difference between first and last tick.\n\nReturns\n\nA scalar representing this duration.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.subset_to_tick","page":"Helper Functions","title":"HighFrequencyCovariance.subset_to_tick","text":"subset_to_tick(ts::SortedDataFrame, n::Integer)\n\nThis subsets a SortedDataFrame to only the first n ticks.\n\nInputs\n\nts - Tick data.\nn - How many ticks to subset to.\n\nReturns\n\nA (smaller) SortedDataFrame.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.subset_to_time","page":"Helper Functions","title":"HighFrequencyCovariance.subset_to_time","text":"subset_to_time(ts::SortedDataFrame, totime::Real)\n\nThis subsets a SortedDataFrame to only the first observations up until some time.\n\nInputs\n\nts - Tick data.\ntotime - Up to what time.\n\nReturns\n\nA (smaller) SortedDataFrame.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#Working-with-CovarianceMatrix-structs","page":"Helper Functions","title":"Working with CovarianceMatrix structs","text":"","category":"section"},{"location":"helper_functions/","page":"Helper Functions","title":"Helper Functions","text":"    covariance\n    get_correlation\n    get_volatility\n    make_nan_covariance_matrix\n    combine_covariance_matrices\n    rearrange\n    cov2cor\n    cor2cov\n    cov2cor_and_vol\n    construct_matrix_from_eigen\n    get_returns\n    valid_correlation_matrix\n    is_psd_matrix","category":"page"},{"location":"helper_functions/#HighFrequencyCovariance.covariance","page":"Helper Functions","title":"HighFrequencyCovariance.covariance","text":"covariance(cm::CovarianceMatrix, duration::Dates.Period)\n\nThis makes a Hermitian matrix for the covariance matrix over some duration.\n\nInputs\n\ncm - A CovarianceMatrix struct.\nperiod - A duration for which you want a covariance matrix. This should be in a Dates.Period.\n\nReturns\n\nA Hermitian.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.get_correlation","page":"Helper Functions","title":"HighFrequencyCovariance.get_correlation","text":"get_correlation(covar::CovarianceMatrix, asset1::Symbol, asset2::Symbol)\n\nExtract the correlation between two assets stored in a CovarianceMatrix.\n\nInputs\n\ncovar - A CovarianceMatrix\nasset1 - A Symbol representing an asset.\nasset2 - A Symbol representing an asset.\n\nReturns\n\nA Scalar (the correlation coefficient).\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.get_volatility","page":"Helper Functions","title":"HighFrequencyCovariance.get_volatility","text":"get_volatility(covar::CovarianceMatrix, asset1::Symbol, time_period_per_unit::Dates.Period = Second(1))\n\nGet the volatility for a stock from a CovarianceMatrix.\n\nInputs\n\ncovar - A CovarianceMatrix\nasset1 - A Symbol representing an asset.\ntime_period_per_unit - The time interval the volatilities will be for.\n\nReturns\n\nA Scalar (the volatility).\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.make_nan_covariance_matrix","page":"Helper Functions","title":"HighFrequencyCovariance.make_nan_covariance_matrix","text":"make_nan_covariance_matrix(labels::Vector{Symbol}, time_period_per_unit::Dates.Period)\n\nThis makes an empty CovarianceMatrix struct with all volatilities and correlations being NaNs.\n\nInputs\n\nlabels - The names of the asset names for this (empty) CovarianceMatrix.\ntime_period_per_unit - The time interval the volatilities will be for.\n\nReturns\n\nAn (empty) CovarianceMatrix\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.combine_covariance_matrices","page":"Helper Functions","title":"HighFrequencyCovariance.combine_covariance_matrices","text":"combine_covariance_matrices(vect::Vector{CovarianceMatrix{T}},\n                            cor_weights::Vector{<:Real} = repeat([1.0], length(vect)),\n                            vol_weights::Vector{<:Real} = cor_weights,\n                            time_period_per_unit::Union{Missing,Dates.Period} = vect[1].time_period_per_unit) where T<:Real\n\nCombines a vector of CovarianceMatrix structs into one CovarianceMatrix struct.\n\nInputs\n\nvect - A vector of CovarianceMatrix structs.\ncor_weights - A vector for how much to weight the correlations from each covariance matrix (by default they will be equalweighted).\nvol_weights - A vector for how much to weight the volatilities from each covariance matrix (by default they will be equalweighted).\ntime_period_per_unit - What time period should the volatilities be scaled to.\n\nReturns\n\nA matrix and a vector of labels for each row/column of the matrix.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.rearrange","page":"Helper Functions","title":"HighFrequencyCovariance.rearrange","text":"rearrange(cm::CovarianceMatrix, labels::Vector{Symbol})\n\nRearrange the order of labels in a CovarianceMatrix.\n\nTakes\n\ncm - A CovarianceMatrix.\nlabels - A Vector of labels.\n\nReturns\n\nA CovarianceMatrix.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.cov2cor","page":"Helper Functions","title":"HighFrequencyCovariance.cov2cor","text":"cov2cor(mat::AbstractMatrix)\n\nConverts a matrix (representing a covariance matrix) into a Hermitian correlation matrix and a vector of standard deviations.\n\nInputs\n\ncor - A matrix.\n\nReturns\n\nA Hermitian.\nA Vector of standard deviations (not volatilities).\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.cor2cov","page":"Helper Functions","title":"HighFrequencyCovariance.cor2cov","text":"cor2cov(cor::AbstractMatrix,sdevs::Vector{<:Real})\n\nConverts a correlation matrix and some standard deviations into a Hermitian covariance matrix.\n\nInputs\n\ncor - A correlation matrix.\nsdevs - A vector of standard deviations (not volatilities).\n\nReturns\n\nA Hermitian.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.cov2cor_and_vol","page":"Helper Functions","title":"HighFrequencyCovariance.cov2cor_and_vol","text":"cov2cor_and_vol(mat::AbstractMatrix, duration_of_covariance_matrix::Dates.Period, duration_for_desired_vols::Dates.Period)\ncov2cor_and_vol(mat::AbstractMatrix, duration_of_covariance_matrix::Real, duration_for_desired_vols::Real)\n\nConverts a matrix (representing a covariance matrix) into a Hermitian correlation matrix and a vector of volatilities.\n\nInputs\n\ncor - A correlation matrix.\nduration_of_covariance_matrix - The duration of the covariance matrix. If these are input as reals they must have the same units.\nduration_for_desired_vols - The duration you want a volatility for. If these are input as reals they must have the same units.\n\nReturns\n\nA Hermitian.\nA Vector of volatilities.\n\ncov2cor_and_vol(mat::AbstractMatrix, duration_of_covariance_matrix_in_nanoseconds::Real, duration_for_desired_vols::Dates.Period)\n\nInputs\n\ncor - A correlation matrix.\nduration_of_covariance_matrix_in_natural_units - The duration of the covariance matrix. It duration must be input in units that you know of (for instance the time_period_per_unit of a SortedDataFrame).\n\nReturns\n\nA Hermitian.\nA Vector of volatilities.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.construct_matrix_from_eigen","page":"Helper Functions","title":"HighFrequencyCovariance.construct_matrix_from_eigen","text":"construct_matrix_from_eigen(eigenvalues::Vector{<:Real},\n                            eigenvectors::Matrix{<:Real})\n\nConstructs a matrix from its eigenvalue decomposition.\n\nInputs\n\neigenvalues - A vector of eigenvalues.\neigenvectors - A matrix of eigenvectors. The i'th column corresponds to the i'th eigenvalue.\n\nReturns\n\nA Matrix.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.get_returns","page":"Helper Functions","title":"HighFrequencyCovariance.get_returns","text":"get_returns(dd::DataFrame; rescale_for_duration::Bool = false)\n\nConverts a long format DataFrame of prices into a DataFrame of returns.\n\nInputs\n\ndd - A DataFrame with a column called :Time and all other columns being asset prices in each period.\nrescale_for_duration - Should returns be rescaled to reflect a common time interval.\n\nReturns\n\nA DataFrame of returns.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.valid_correlation_matrix","page":"Helper Functions","title":"HighFrequencyCovariance.valid_correlation_matrix","text":"valid_correlation_matrix(mat::Hermitian)\nvalid_correlation_matrix(covar::CovarianceMatrix)\n\nTest if a Hermitian matrix is a valid correlation matrix. This is done by testing if it is psd, if it has a unit diagonal and if all other elements are less than one. If a Hermitian is input then it will be tested. If a CovarianceMatrix is input then its correlation matrix will be tested.\n\nInputs\n\nA Hermitian matrix or a CovarianceMatrix\n\nReturns\n\nA Bool that is true if mat is a valid correlation matrix and false if not.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.is_psd_matrix","page":"Helper Functions","title":"HighFrequencyCovariance.is_psd_matrix","text":"is_psd_matrix(mat::Hermitian)\nis_psd_matrix(covar::CovarianceMatrix)\n\nTest if a matrix is psd (Positive Semi-Definite). This is done by seeing if all eigenvalues are positive. If a Hermitian is input then it will be tested. If a CovarianceMatrix is input then its correlation matrix will be tested.\n\nInputs\n\nA Hermitian matrix or a CovarianceMatrix\n\nReturns\n\nA Bool that is true if mat is psd and false if not.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#Blocking-and-Regularisation-Functions","page":"Helper Functions","title":"Blocking and Regularisation Functions","text":"","category":"section"},{"location":"helper_functions/","page":"Helper Functions","title":"Helper Functions","text":"    put_assets_into_blocks_by_trading_frequency\n    blockwise_estimation","category":"page"},{"location":"helper_functions/#HighFrequencyCovariance.put_assets_into_blocks_by_trading_frequency","page":"Helper Functions","title":"HighFrequencyCovariance.put_assets_into_blocks_by_trading_frequency","text":"put_assets_into_blocks_by_trading_frequency(ts::SortedDataFrame,\n                                            obs_multiple_for_new_block::Real, func::Symbol,\n                                            optional_parameters::NamedTuple = NamedTuple())\n\nThis makes a DataFrame that describes how to estimate the covariance matrix blockwise.\n\nInputs\n\nts - The tick data.\nobs_multiple_for_new_block - The relative number of ticks needed before a new block is made. So if this is 1.2 that means a new group is made when one asset has 20% or more ticks than the slowest traded asset in the previous block.\nfunc - A symbol representing the covariance estimation function to be used.\noptional_parameters - Optional parameters to be used in the func function.\n\nReturns\n\nA DataFrame representing what estimations should be performed. The order of rows in the DataFrame shows the order of estimation.\n\nReferences\n\nHautsch, N., Kyj, L.M. and Oomen, R.C.A. (2012), A blocking and regularization approach to high‐dimensional realized covariance estimation. J. Appl. Econ., 27: 625-645\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.blockwise_estimation","page":"Helper Functions","title":"HighFrequencyCovariance.blockwise_estimation","text":"blockwise_estimation(ts::SortedDataFrame, blocking_frame::DataFrame)\n\nRun a series of covariance estimations and combine the results. Two things should be input, a SortedDataFrame with the price update data and a dataframe describing what estimations should be performed. This should be of the same form as is output by put_assets_into_blocks_by_trading_frequency (although the actual estimations can be customised to something different as to what that function outputs).\n\nInputs\n\nts - The tick data.\nblocking_frame - A DataFrame representing what estimations to do and in what order. This is often be one generated by the put_assets_into_blocks_by_trading_frequency function (and potentially then modified).\n\nReturns\n\nA CovarianceMatrix.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#Monte-Carlo","page":"Helper Functions","title":"Monte Carlo","text":"","category":"section"},{"location":"helper_functions/","page":"Helper Functions","title":"Helper Functions","text":"    generate_random_path\n    ItoSet","category":"page"},{"location":"helper_functions/#HighFrequencyCovariance.generate_random_path","page":"Helper Functions","title":"HighFrequencyCovariance.generate_random_path","text":"generate_random_path(dimensions::Integer, ticks::Integer; syncronous::Bool = false,\n                     twister::MersenneTwister = MersenneTwister(1),\n                     vol_dist::Distribution = Uniform(0.1/sqrt(252 * 8 * 3600), 0.5/sqrt(252 * 8 * 3600)),\n                     refresh_rate_dist::Distribution    = Uniform(0.5, 5.0),\n                     time_period_per_unit::Dates.Period = Second(1),\n                     micro_noise_dist::Distribution     = Uniform(vol_dist.a * sqrt(time_period_ratio(Minute(15), time_period_per_unit)), vol_dist.b * sqrt(time_period_ratio(Minute(15), time_period_per_unit))),\n                     assets::Union{Vector,Missing}      = missing,\n                     brownian_corr_matrix::Union{Hermitian,Missing} = missing,\n                     vols::Union{Vector,Missing}        = missing)\n\nGenerate a random path of price updates with a specified number of dimensions and ticks. There are options for whether the data is syncronous or asyncronous, the volatility of the price processes, the refresh rate on the (exponential) arrival times of price updates, the minimum and the maximum microstructure noises.\n\nNote the defaults are chosen to reflect a highcap stock with annulised volatility between 10% and 50%. Microstructure noise is equal to 15 minutes standard deviation of return. vol * sqrt(60*15) Refreshed ticks every 0.5-5 seconds (in expectation).\n\nInputs\n\ndimensions - The number of assets.\nticks - The number of ticks to produce.\nsyncronous - Should ticks be syncronous (for each asset) or asyncronous.\ntwister - The MersenneTwister used for RNG.\nvol_dist - The distribution to draw volatilities from (only used if vols is missing).\nrefresh_rate_dist - The distribution to draw refresh rates (exponential distribution rates) from.\ntime_period_per_unit - What time period should the time column correspond to.\nmicro_noise_dist  - The distribution to draw assetwise microstructure noise variances from.\nassets - The names of the assets that you want to use. The length of this must be equal to the dimensions input.\nbrownian_corr_matrix - The correlation matrix to use. This is sampled from the Inverse Wishart distribution if none is input.\nvols - The volatilities to use. These are sampled  from the uniform distribution between min_noise_var and max_noise_var.\n\nReturns\n\nA SortedDataFrame of tick data.\nA CovarianceMatrix representing the true data generation process used in making the tick data.\nA Dict of microstructure noise variances for each asset.\nA Dict of update rates for each asset.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#StochasticIntegrals.ItoSet","page":"Helper Functions","title":"StochasticIntegrals.ItoSet","text":"ItoSet(covariance_matrix::CovarianceMatrix{<:Real})\n\nConvert a CovarianceMatrix into an ItoSet from the StochasticIntegrals package. This package can then be used to do things like generate draws from the Multivariate Gaussian corresponding to the covariance matrix and other things.\n\nInputs\n\ncovariance_matrix - The CovarianceMatrix that you want to convert into an StochasticIntegrals.ItoSet\n\nReturns\n\nA StochasticIntegrals.ItoSet struct.\n\n\n\n\n\n","category":"type"},{"location":"helper_functions/#For-getting-a-DataFrame-version-of-a-CovarianceMatrix-and-vice-versa.","page":"Helper Functions","title":"For getting a DataFrame version of a CovarianceMatrix and vice versa.","text":"","category":"section"},{"location":"helper_functions/","page":"Helper Functions","title":"Helper Functions","text":"    HighFrequencyCovariance.to_dataframe\n    dataframe_to_covariancematrix","category":"page"},{"location":"helper_functions/#StochasticIntegrals.to_dataframe","page":"Helper Functions","title":"StochasticIntegrals.to_dataframe","text":"to_dataframe(covar::CovarianceMatrix, othercols::Dict = Dict{Symbol,Any}();\n             delete_duplicate_correlations::Bool = true)\n\nConvert a CovarianceMatrix to a DataFrame format.\n\nInputs\n\ncovar - The CovarianceMatrix\nothercols - This adds columns to the DataFrame. For instance if it is Dict{Symbol,String}([:pc] .=> [\"Fred's PC\"]), then there will be a column indicating that this estimation was done on Fred's PC.\ndelete_duplicate_correlations - Should the unnecessary correlations be included (as correlation matrices are symmetric half the entries duplicate information).\n\nReturns\n\nA DataFrame.\n\n\n\n\n\n","category":"function"},{"location":"helper_functions/#HighFrequencyCovariance.dataframe_to_covariancematrix","page":"Helper Functions","title":"HighFrequencyCovariance.dataframe_to_covariancematrix","text":"dataframe_to_covariancematrix(dd::DataFrame)\n\nConvert a CovarianceMatrix to a DataFrame format.\n\nInputs\n\ndd - A DataFrame of the form generated by the to_dataframe function.\n\nReturns\n\nA CovarianceMatrix struct.\n\n\n\n\n\n","category":"function"},{"location":"2_data_structures/#Data-Structures","page":"Data Structures","title":"Data Structures","text":"","category":"section"},{"location":"2_data_structures/#Main-Structs","page":"Data Structures","title":"Main Structs","text":"","category":"section"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"HighFrequencyCovariance has two main structs. The first is CovarianceMatrix which is:","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"mutable struct CovarianceMatrix{R<:Real}\n    correlation::Hermitian{R}\n    volatility::Vector{R}\n    labels::Vector{Symbol}\nend","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"A CovarianceMatrix struct thus contains three elements. A correlation matrix, a volatility vector and a vector that labels each row/column of the correlation matrix and each row of the volatility vector. Note that an actual covariance matrix is not stored but can be calculated over some interval with the function:","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"covariance(cm::CovarianceMatrix, duration::Real)","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"The second main struct is a SortedDataFrame which is:","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"struct SortedDataFrame\n    df::DataFrame\n    time::Symbol\n    grouping::Symbol\n    value::Symbol\n    groupingrows::Dict{Symbol,Vector{Int64}}\nend","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"This presorts a DataFrame by time and adds in an index (groupingrows) for each asset. Together these allow the covariance estimation functions to run faster. The other struct elements are the labels of the columns of interest in the DataFrame.","category":"page"},{"location":"1_algorithms/#Algorithms","page":"Algorithms","title":"Algorithms","text":"","category":"section"},{"location":"1_algorithms/#Volatility","page":"Algorithms","title":"Volatility","text":"","category":"section"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"There are two built-in algorithms that purely estimate volatility. These are:","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"simple_volatility estimates the volatility for each stock given a grid of sampling times. If a grid of sampling times is not input then one is estimated optimally (using a formula suggested by Zhang, Mykland & Aït-Sahalia 2005).\ntwo_scales_volatility estimates volatility over two different timescales. One is over a short duration (so a large amount of the measured variation will be from microstructure noise) and one is over a longer duration (so little of the measured variation is from microstructure noise). Then it combines the two estimates to get an estimate of volatility and also of microstructure noise (For how this is done see Zhang, Mykland & Aït-Sahalia 2005).","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"These two functions can be called directly or through the estimate_volatility function. In the estimate_volatility function the method can be specified as either :simple_volatility or :two_scales_volatility.","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"In addition it is generally possible to infer volatility from the covariance matrix estimates. Given a covariance matrix over some interval it is possible to extract the variance of each stock's price and then determine the volatility from that. In most cases when one of the following covariance estimation function is use it is this measure of volatility that is put into the CovarianceMatrix struct.","category":"page"},{"location":"1_algorithms/#Covariance","page":"Algorithms","title":"Covariance","text":"","category":"section"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"There are five algorithms for estimating covariances.","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"The simple_covariance function estimates a covariance matrix in the basic way using a given timegrid. Users can input their own timegrid, their own interval spacing that will be used to make a timegrid or they can choose to use refresh times (which will likely be biased and so is not recommended). If a user does not do this then by default the spacing will be the average (across assets) optimal spacing that is calculated in the simple_volatility function.\nThe preaveraged_covariance function. This first preaverages price updates over certain intervals and then estimates the correlations using the averaged series. As a result of averaging the microstructure noise is reduced and the correlations are more accurate as a result. As the volatilities of preaveraged returns are artificially low we use two scales volatility estimates for volatility in this case (Christensen, Podolskij and Vetter 2013).\nThe two_scales_covariance function. This calculates volatilities using the two_scales_volatility estimator. It then calculated pairwise correlations by comparing the two scales volatility of different linear combinations of the two assets (Ait-Sahalia, Fan and Xiu 2010).\nThe spectral_covariance function - The spectral local method of moments technique  (Bibinger, Hautsch, Malec, and Reiss 2014) starts by breaking the trading period into equally sized subintervals. Given each subinterval we  compute a spectral statistic matrix by using a weighted summation of the returns within that interval. We calculate these weights by means of an orthogonal sine function with some spectral frequency j. Then we gather many different spectral statistic matrices by doing this repeatedly with different spectral frequencies. Our estimate of the covariance matrix is then calculated as the average of these spectral statistics.\nThe bnhls_covariance function - The multivariate realised kernel (Barndorff-Nielsen, Hansen, Lunde, and Shephard 2008 - sometimes called the BNHLS method after the authors) is an algorithm that is designed to provide consistent PSD covariance estimates despite settings where there is microstructure noise (that may not be independent of the underlying price process) and asyncronously traded assets. It is a refinement of an earlier algorithm, the univariate realised kernel estimator, which is faster converging but relies on an assumption of independence between microstructure noise and the underlying price process.","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"These five functions can be called directly or through the estimate_covariance function. In the estimate_covariance function the method can be specified as :simple_covariance, :preaveraged_covariance, :two_scales_covariance, :spectral_covariance or :bnhls_covariance.","category":"page"},{"location":"1_algorithms/#Regularisation","page":"Algorithms","title":"Regularisation","text":"","category":"section"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"There are four inbuilt regularisation algorithms, identity_regularisation, eigenvalue_clean, nearest_psd_matrix and nearest_correlation_matrix. The first three of these can be applied to either the covariance matrix or to the correlation matrix while the fourth can only be applied to the correlation matrix. If input as a regularisation method to a covariance estimation function, these methods can regularise a covariance matrix before it is split into a correlation matrix and volatilities. It can also be applied purely to the resultant correlation matrix. These regularisation techniques can also be applied directly to a CovarianceMatrix struct either on the correlation matrix or covariance matrix (in which case a covariance matrix is constructed, regularised and then split into a correlation matrix and volatilities that are then placed in a CovarianceMatrix struct).","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"The regularisation techniques are:","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"identity_regularisation regularises a covariance (or correlation) by averaging it with an identity matrix of the same dimensions (Ledoit and Wolf 2001).\neigenvalue_clean splits a covariance (or correlation) matrix into its eigenvalue decomposition. Then the distribution of eigenvalues that would be expected if it were a random matrix is computed. Any eigenvalues that are sufficiently small that they could have resulted from a random matrix are averaged together which shrinks their impact while the covariance matrix is still psd (Laloux, Cizeau, Bouchaud and Potters 1999).\nnearest_psd_matrix maps an estimated matrix to the nearest PSD (Positive Semi Definite) matrix (Higham 2002).\nnearest_correlation_matrix maps an estimated correlation matrix to the nearest PSD matrix. And then the nearest unit diagonal (with off-diagonals less than one in absolute value) matrix. Then the nearest PSD matrix and so on until it converges. The result is the nearest valid correlation matrix.","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"These four functions can be called directly or through the regularise function. In this function the method can be specified as :identity_regularisation, :eigenvalue_clean, :nearest_psd_matrix or :nearest_correlation_matrix.","category":"page"},{"location":"9_references/#References","page":"References","title":"References","text":"","category":"section"},{"location":"9_references/","page":"References","title":"References","text":"Ait-Sahalia Y, Fan J, Xiu D (2010). \"High-Frequency Covariance Estimates With Noisy and Asynchronous Financial Data.\" Journal of the American Statistical Association, 105(492), 1504–1517. doi:10.1198/jasa.2010.tm10163.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Barndorff-Nielsen OE, Hansen PR, Lunde A, Shephard N (2011). \"Multivariate realised kernels: consistent positive semi-definite estimators of the covariation of equity prices with noise and non-synchronous trading.\" Journal of Econometrics, 162(2), 149–169. doi:10.1016/j.jeconom.2010.07.009.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Baumann S, Klymak, M. (2021) \"HighFrequencyCovariance: A Julia Package for Estimating Covariance Matrices Using High Frequency Financial Data.\" SSRN paper 3786912 available at  https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3786912","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Bibinger M, Hautsch N, Malec P, Reiss M (2014). \"Estimating the quadratic covariation matrix from noisy observations: Local method of moments and efficiency.\" The Annals of Statistics, 42(4), 1312–1346. doi:10.1214/14-AOS1224.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Christensen K, Podolskij M, Vetter M (2013). \"On covariation estimation for multivariate continuous Itô semimartingales with noise in non-synchronous observation schemes.\" Journal of Multivariate Analysis, 120, 59–84. doi:10.1016/j.jmva.2013.05.002.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Eps T (1979). \"Comovements in stock prices in the very short run.\" Journal of the American Statistical Association, 74, 291–296. doi:10.1080/01621459.1979.10482508.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Hautsch N, Kyj LM, Oomen RCA (2012). \"A blocking and regularization approach to high-dimensional realized covariance estimation.\" Journal of Applied Econometrics, 27(4), 625–645. doi:10.1002/jae.1218.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Higham NJ (2002). \"Computing the nearest correlation matrix - a problem from finance.\" IMA Journal of Numerical Analysis, 22, 329–343. doi:10.1002/nla.258.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Laloux L, Cizeau P, Bouchaud JP, Potters M (1999). \"Noise Dressing of Financial Correlation Matrices.\" Physical Review Letters, 83(7), 1467–1470. ISSN 1079-7114. doi:10.1103/physrevlett.83.1467.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Ledoit O, Wolf M (2001). \"A well-conditioned estimator for large-dimensional covariance matrices.\" Journal of Multivariate Analysis, 88(2), 365–411. doi:10.1016/S0047-259X(03)00096-4.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Zhang L, Mykland PA, Aït-Sahalia Y (2005). \"A Tale of Two Time Scales: Determining Integrated Volatility with Noisy High-Frequency Data.\" Journal of the American Statistical Association, 100(472), 1394–1411. ISSN 01621459. doi:10.1198/016214505000000169.","category":"page"},{"location":"#HighFrequencyCovariance","page":"Introduction","title":"HighFrequencyCovariance","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"This package estimates covariance matrix using high frequency data.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"This task is more complicated than normal covariance estimation due to several features of high frequency financial data:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Assets are traded nonsyncronously. For instance we get an updated GOOG price at 14:28:00 and then get an updated price for MSFT only at 14:28:04. Ignoring the asynchronisity with which we get price updates can downwards bias correlations (Eps 1979).\nPrice updates typically contain some \"microstructure noise\" which reflects frictions in the market rather than the longterm correlations between assets.\nThe microstruture noise can often not be iid but can exhibit serial correlation.\nOften more advanced techniques that adjust for the above issues are not guaranteed to return a PSD covariance matrix. So we need to regularise.\nAssets may be traded over different intervals. For instance in calculating the correlation between JP Morgan and Credit Suisse we might have some days where Credit Suisse does  trade in Zurich but due to thanksgiving JP Morgan is not being traded in New York. So we might need to assemble a covariance matrix where the pairwise covariances/correlations come from slightly different intervals. This can lead to a resultant matrix that is not positive semi definite regardless of the estimation method.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"HighFrequencyCovariance contains 2 volatility estimators, 5 covariance estimators, 4 regularisation techniques and a number of convenience functions that are intended to overcome these issues and produce reliable correlation, volatility and covariance estimates given high frequency financial data.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"A paper (Baumann & Klymak 2021) briefly outlining each technique is accessible. This paper also contains references to the original econometrics papers for users that seek a more detailed understanding.  The paper also contains a Monte Carlo analysis of the accuracy and time complexity of each algorithm. This documentation will not replicate all of that content and will instead focus on the practical details on how to write code to use this package.","category":"page"},{"location":"internals/","page":"Internal Functions","title":"Internal Functions","text":"CurrentModule = HighFrequencyCovariance","category":"page"},{"location":"internals/#Internal-Functions","page":"Internal Functions","title":"Internal Functions","text":"","category":"section"},{"location":"internals/","page":"Internal Functions","title":"Internal Functions","text":"Pages = [\"internals.md\"]","category":"page"},{"location":"internals/#Metrics-for-distances-between-CovarianceMatrix-structs","page":"Internal Functions","title":"Metrics for distances between CovarianceMatrix structs","text":"","category":"section"},{"location":"internals/","page":"Internal Functions","title":"Internal Functions","text":"    calculate_mean_abs_distance\n    squared_frobenius\n    squared_frobenius_distance","category":"page"},{"location":"internals/#HighFrequencyCovariance.calculate_mean_abs_distance","page":"Internal Functions","title":"HighFrequencyCovariance.calculate_mean_abs_distance","text":"calculate_mean_abs_distance(cov1::CovarianceMatrix, cov2::CovarianceMatrix, decimal_places::Integer)\n\nCalculates the mean absolute distance (elementwise in L1 norm) between two CovarianceMatrixs. Undefined if any labels differ between the two CovarianceMatrixs.\n\nInputs\n\ncov1 - The first CovarianceMatrix\ncov2 - The second CovarianceMatrix\ndecimal_places - How many decimal places to show the result to.\n\nReturns\n\nAn Tuple with the distance for correlations in first entry and distance for volatilities in the second.\n\ncalculate_mean_abs_distance(d1::Dict{Symbol,<:Real}, d2::Dict{Symbol,<:Real})\n\nCalculates the mean absolute distance (elementwise in L1 norm) between two CovarianceMatrixs.\n\nInputs\n\nd1 - The first Dict\nd2 - The second Dict\n\nReturns\n\nA scalar with the mean distance between matching elements.\n\n\n\n\n\n","category":"function"},{"location":"internals/#HighFrequencyCovariance.squared_frobenius","page":"Internal Functions","title":"HighFrequencyCovariance.squared_frobenius","text":"squared_frobenius(x1::AbstractMatrix)\n\nRearrange the squared frobenius norm of a matrix. Returns a real.\n\nInputs\n\nx1 The matrix that you want the squared frobenius norm for.\n\nReturns\n\nA Scalar.\n\n\n\n\n\n","category":"function"},{"location":"internals/#HighFrequencyCovariance.squared_frobenius_distance","page":"Internal Functions","title":"HighFrequencyCovariance.squared_frobenius_distance","text":"squared_frobenius_distance(x1::AbstractMatrix, x2::AbstractMatrix = x1)\n\nRearrange the squared frobenius distance between two matrices. Returns a real.\n\nInputs\n\nx1 The first matrix.\nx2 The second matrix.\n\nReturns\n\nA Scalar.\n\n\n\n\n\n","category":"function"},{"location":"internals/#Used-in-volatility-estimation-techniques","page":"Internal Functions","title":"Used in volatility estimation techniques","text":"","category":"section"},{"location":"internals/","page":"Internal Functions","title":"Internal Functions","text":"    default_num_grids","category":"page"},{"location":"internals/#HighFrequencyCovariance.default_num_grids","page":"Internal Functions","title":"HighFrequencyCovariance.default_num_grids","text":"default_num_grids(ts::SortedDataFrame)\n\nThis gives a default number of intervals to divide a series of ticks over for the purposes of estimating returns and volatility.\n\nInputs\n\nts - The tick data.\n\nReturns\n\nAn integer for the number of intervals.\n\n\n\n\n\n","category":"function"},{"location":"internals/#Used-in-covariance-estimation-techniques","page":"Internal Functions","title":"Used in covariance estimation techniques","text":"","category":"section"},{"location":"internals/","page":"Internal Functions","title":"Internal Functions","text":"    get_all_refresh_times\n    latest_value\n    time_between_refreshes\n    random_value_in_interval","category":"page"},{"location":"internals/#HighFrequencyCovariance.get_all_refresh_times","page":"Internal Functions","title":"HighFrequencyCovariance.get_all_refresh_times","text":"get_all_refresh_times(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts);\n                      start_time::R = minimum(ts.df[:,ts.time])) where R<:Real\n\nGet a vector of all refresh times when all assets have an updated price. So if there are assets A and B that trade at times (1,5,6,7,10) and (2,5,7,9) then the refresh times are (2,5,7,10) as at these four times there are updated prices for all assets that have happened since the previous refresh time.\n\nInputs\n\nts - The tick data.\nassets - The assets of interest.\nstart_time - From what time should we start looking for updated prices.\n\nReturns\n\nA Vector of refresh times.\n\n\n\n\n\n","category":"function"},{"location":"internals/#HighFrequencyCovariance.latest_value","page":"Internal Functions","title":"HighFrequencyCovariance.latest_value","text":"latest_value(ts::SortedDataFrame, at_times::Vector{<:Real};\n             assets::Vector{Symbol} = get_assets(ts))\n\nGet the latest price at a each input time.\n\nInputs\n\nts - The tick data.\nat_times - The times you want the latest prices for.\nassets - The assets you want latest prices for.\n\nReturns\n\nA DataFrame. Rows are for each time specified in at_times. Columns are for each asset.\n\n\n\n\n\n","category":"function"},{"location":"internals/#HighFrequencyCovariance.time_between_refreshes","page":"Internal Functions","title":"HighFrequencyCovariance.time_between_refreshes","text":"time_between_refreshes(ts::SortedDataFrame;\n                       assets::Vector{Symbol} = get_assets(ts))\n\nGet a DataFrame showing how many time is between each refresh and how many ticks in total.\n\nInputs\n\nts - Tick data.\nassets - A Vector of labels.\n\nReturns\n\nA DataFrame summarising the average number of time between ticks for each asset.\n\n\n\n\n\n","category":"function"},{"location":"internals/#HighFrequencyCovariance.random_value_in_interval","page":"Internal Functions","title":"HighFrequencyCovariance.random_value_in_interval","text":"random_value_in_interval(ts::SortedDataFrame, at_times::Vector{<:Real};\n                         assets::Vector{Symbol} = get_assets(ts),\n                         twister_arb_value_in_interval::MersenneTwister = MersenneTwister(2604))\n\nGet a random value in an interval. So if you input times 1,7,8 then for the second entry it will pick a random update (if any exist) between times 1 and 7.\n\nInputs\n\nts - The tick data.\nat_times - The times that seperate the intervals of interest.\nassets - The assets of interest.\ntwister_arb_value_in_interval - The RNG used in selecting the random interval.\n\nReturns\n\nA DataFrame with prices for each asset from random ticks in each interval.\n\n\n\n\n\n","category":"function"},{"location":"internals/#Kernels-used-in-the-BNHLS-method","page":"Internal Functions","title":"Kernels used in the BNHLS method","text":"","category":"section"},{"location":"internals/","page":"Internal Functions","title":"Internal Functions","text":"    HFC_Kernel\n    parzen\n    quadratic_spectral\n    fejer\n    tukey_hanning\n    bnhls_2008","category":"page"},{"location":"internals/#HighFrequencyCovariance.HFC_Kernel","page":"Internal Functions","title":"HighFrequencyCovariance.HFC_Kernel","text":"A kernel used in the bnhls covariance method.\n\n\n\n\n\n","category":"type"},{"location":"internals/#HighFrequencyCovariance.parzen","page":"Internal Functions","title":"HighFrequencyCovariance.parzen","text":"A parzen kernel used in the bnhls covariance method.\n\n\n\n\n\n","category":"constant"},{"location":"internals/#HighFrequencyCovariance.quadratic_spectral","page":"Internal Functions","title":"HighFrequencyCovariance.quadratic_spectral","text":"A quadratic_spectral kernel used in the bnhls covariance method.\n\n\n\n\n\n","category":"constant"},{"location":"internals/#HighFrequencyCovariance.fejer","page":"Internal Functions","title":"HighFrequencyCovariance.fejer","text":"A fejer kernel used in the bnhls covariance method.\n\n\n\n\n\n","category":"constant"},{"location":"internals/#HighFrequencyCovariance.tukey_hanning","page":"Internal Functions","title":"HighFrequencyCovariance.tukey_hanning","text":"A tukey_hanning kernel used in the bnhls covariance method.\n\n\n\n\n\n","category":"constant"},{"location":"internals/#HighFrequencyCovariance.bnhls_2008","page":"Internal Functions","title":"HighFrequencyCovariance.bnhls_2008","text":"A bnhls_2008 kernel used in the bnhls covariance method.\n\n\n\n\n\n","category":"constant"},{"location":"internals/#Used-in-nearest-correlation-regularisation","page":"Internal Functions","title":"Used in nearest correlation regularisation","text":"","category":"section"},{"location":"internals/","page":"Internal Functions","title":"Internal Functions","text":"    project_to_S\n    project_to_U\n    iterate_higham","category":"page"},{"location":"internals/#HighFrequencyCovariance.project_to_S","page":"Internal Functions","title":"HighFrequencyCovariance.project_to_S","text":"project_to_S(A::Hermitian, W_root::Union{Hermitian,Diagonal};\n             W_inv_sqrt::Union{Hermitian,Diagonal} = sqrt_psd(inv(W_root^2)))\nproject_to_S(A::Diagonal, W_root::Union{Hermitian,Diagonal};\n             W_inv_sqrt::Union{Hermitian,Diagonal,Missing} = missing)\n\nThis maps a matrix to the nearest psd matrix. Wroot should be the principal square root of a psd Hermitian weighting matrix, W. `Winvsqrtshould be the corresponding square root of the inverse of W.nearestpsd_matrix` is a simpler interface for this function however it does not allow weighting matrices to be specified.\n\nInputs\n\nA - The matrix you want to project to the S space. This can be a Diagonal or a Hermitian. Note that if you input a Diagonal matrix then it is already in the S space and so it will be returned without any calculation.\nW_root - The inverse weighting matrix.\nW_inv_sqrt - The root of W_root. This is calculated if you don't have it but it can save some calculation effort if you already have it.\n\nOutputs\n\nA Hermitian.\n\nReferences\n\nHigham, N. J. 2001. Theorem 3.2\n\n\n\n\n\n","category":"function"},{"location":"internals/#HighFrequencyCovariance.project_to_U","page":"Internal Functions","title":"HighFrequencyCovariance.project_to_U","text":"project_to_U(A::Union{Diagonal,Hermitian}, invW::Hermitian)\n\nThis maps the Hermitian/Hermitian matrix A to the nearest matrix in the U space (the space of all unit diagonal matrices as defined by Higham 2001). The inverse weight matrix invW determines how much to adjust each element to get it to be unit diagonal. In other words it is used to determine what is the nearest correlation matrix. The weight matrix must be Hermitian positive definite. We use the W-norm (as defined by Higham 2001).\n\nInputs\n\nA - The matrix you want to project to the U space\ninvW - The inverse weighting matrix.\n\nOutputs\n\nA Diagonal or a Hermitian.\n\nReferences\n\nHigham, N. J. 2001. Bottom of page 335.\n\n\n\n\n\n","category":"function"},{"location":"internals/#HighFrequencyCovariance.iterate_higham","page":"Internal Functions","title":"HighFrequencyCovariance.iterate_higham","text":"iterate_higham(Y::Union{Hermitian,Diagonal}, Dykstra::Union{Hermitian,Diagonal},\n               W_root::Union{Hermitian,Diagonal}, W_inv::Union{Hermitian,Diagonal},\n               W_inv_sqrt::Union{Hermitian,Diagonal})\n\nDo one iterate mapping the input matrix to the S space (of psd matrices) and then to the U space (unit diagonal and all other entries below 1 in absolute value). Returns the updated matrix and the next iterate's Dykstra correction.\n\nInputs\n\nY - The matrix you want to project to the iterate towards the space of valid correlation matrices.\nDykstra - The Dykstra correction matrix.\nW_root - The root of W.\nW_inv - The inverse of W.\nW_inv_sqrt - The root of the inverse of W.\n\nOutputs\n\nA Hermitian.\nAn updated Dykstra correction matrix.\n\nReferences\n\nHigham, N. J. 2001. Algorithm 3.3\n\n\n\n\n\n","category":"function"}]
}
