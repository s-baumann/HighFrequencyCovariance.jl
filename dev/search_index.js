var documenterSearchIndex = {"docs":
[{"location":"functions/","page":"Functions","title":"Functions","text":"CurrentModule = HighFrequencyCovariance","category":"page"},{"location":"functions/#Functions","page":"Functions","title":"Functions","text":"","category":"section"},{"location":"functions/","page":"Functions","title":"Functions","text":"Pages = [\"functions.md\"]","category":"page"},{"location":"functions/#Estimating-Covariance-Matrices","page":"Functions","title":"Estimating Covariance Matrices","text":"","category":"section"},{"location":"functions/","page":"Functions","title":"Functions","text":"simple_covariance\nbnhls_covariance\nspectral_covariance\npreaveraged_covariance\ntwo_scales_covariance","category":"page"},{"location":"functions/#HighFrequencyCovariance.simple_covariance","page":"Functions","title":"HighFrequencyCovariance.simple_covariance","text":"     simple_covariance(ts::SortedDataFrame, assets::Vector{Symbol} = get_assets(ts); regularisation::Union{Missing,Symbol} = :covariance_default, regularisation_params::Dict = Dict(),\n                       only_regulise_if_not_PSD::Bool = false, time_grid::Union{Missing,Vector} = missing,\n                       fixed_spacing::Union{Missing,<:Real} = missing, refresh_times::Bool = false, rough_guess_number_of_intervals::Integer = 5)\n\nEstimation of the covariance matrix in the standard simple way. https://en.wikipedia.org/wiki/Samplemeanand_covariance\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.bnhls_covariance","page":"Functions","title":"HighFrequencyCovariance.bnhls_covariance","text":"This calculates covariance with the Multivariate realised kernel oof BNHLS(2011) Barndorff-Nielsen, O., Hansen, P.R., Lunde, A., Shephard, N. 2011. - The whole paper but particularly 2.2, 2.3 here. Kernels are in table 1. choices of H are discussed in section 3.4 of the paper.\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.spectral_covariance","page":"Functions","title":"HighFrequencyCovariance.spectral_covariance","text":"Estimation of a CovarianceMatrix using the spectral covariance method. Bibinger M, Hautsch N, Malec P, Reiss M (2014). “Estimating the quadratic covariation matrix from noisy observations: Local method of moments and efficiency.” The Annals of Statistics, 42(4), 1312–1346. doi:10.1214/14-AOS1224.\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.preaveraged_covariance","page":"Functions","title":"HighFrequencyCovariance.preaveraged_covariance","text":"Estimation of the CovarianceMatrix using preaveraging method. Christensen K, Podolskij M, Vetter M (2013). “On covariation estimation for multivariate continuous Itô semimartingales with noise in non-synchronous observation schemes.” Journal of Multivariate Analysis, 120, 59–84. doi:10.1016/j.jmva.2013.05.002.\n\n\n\n\n\n","category":"function"},{"location":"functions/#HighFrequencyCovariance.two_scales_covariance","page":"Functions","title":"HighFrequencyCovariance.two_scales_covariance","text":"Estimation of a CovarianceMatrix using the two scale covariance method.\n\n\n\n\n\n","category":"function"},{"location":"3_WritingCode/#Using-HighFrequencyCovariance","page":"Writing Code","title":"Using HighFrequencyCovariance","text":"","category":"section"},{"location":"3_WritingCode/#Loading-in-data","page":"Writing Code","title":"Loading in data","text":"","category":"section"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We first load our data into a dataframe. As an example we have a dataframe of price updates (like that in df below). Then we can put our data into a SortedDataFrame by putting the dataframe and the names of the time, label and value columns into the constructor:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"using HighFrequencyCovariance\nusing DataFrames\ndf = DataFrame(:stock => [:A,:B,:A,:A,:A,:B,:A,:B,:B], :time => [1,2,3,4,5,5,6,7,8],\n               :logprice => [1.01,2.0,1.011,1.02,1.011,2.2,1.0001,2.2,2.3])\nts = SortedDataFrame(df, :time, :stock, :logprice)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"In a real setting this is how we would turn our dataframe of data into a SortedDataFrame.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"For the succeeding sections it is useful to get more realistic time series data. So we will generate some Monte Carlo data here using the generate_random_path function which generates a random correlation matrix, volatilities, price update times and microstructure noises and generates a SortedDataFrame from a random time series consistent with these.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"using HighFrequencyCovariance\nusing Random\ndims = 4\nticks = 10000\nts, true_covar, true_micro_noise, true_update_rates = generate_random_path(dims, ticks, twister = MersenneTwister(2))","category":"page"},{"location":"3_WritingCode/#Estimating-Volatility","page":"Writing Code","title":"Estimating Volatility","text":"","category":"section"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We can use the SortedDataFrame we have generated (in the ts variable) to estimate the volatility of each asset:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"assets         = get_assets(ts)\nsimple_vol     = estimate_volatility(ts, assets, :simple_volatility)\ntwo_scales_vol = estimate_volatility(ts, assets, :two_scales_volatility)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Now the true volatility is contained in true_covar.volatility. We can present these true volatilities alongside the two estimated volatilities","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"using DataFrames\ntrue_volatility = Dict{Symbol,Float64}(true_covar.labels .=> true_covar.volatility)\nsummary_frame = vcat(DataFrame.([true_volatility, simple_vol, two_scales_vol] )... )\nsummary_frame = hcat(DataFrame(Dict(:estimation => [\"True\", \"Simple\", \"2 Scales\"])), summary_frame)\nprint(summary_frame)\n# │ Row │ estimation │ asset_1   │ asset_2   │ asset_3    │ asset_4   │\n# │     │ String     │ Float64   │ Float64   │ Float64    │ Float64   │\n# ├─────┼────────────┼───────────┼───────────┼────────────┼───────────┤\n# │ 1   │ True       │ 0.0157077 │ 0.0137856 │ 0.00484516 │ 0.0142265 │\n# │ 2   │ Simple     │ 0.0178855 │ 0.0284619 │ 0.00502814 │ 0.0129842 │\n# │ 3   │ 2 Scales   │ 0.0173682 │ 0.0192129 │ 0.00605092 │ 0.0149015 │","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We can see that the accuracy of the simple method was particularly bad for asset_2.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"This is due to microstructure noise which we can estimate as:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"noise          = estimate_microstructure_noise(ts, assets)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"And tabling the estimated and true microstructure noise we can see that there was more microstructure noise for asset_2 relative to the other assets.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"using DataFrames\nsummary_frame = vcat(DataFrame.([true_micro_noise, noise] )... )\nsummary_frame = hcat(DataFrame(Dict(:estimation => [\"True\", \"2 Scales noise estimate\"])), summary_frame)\nprint(summary_frame)\n# 2×5 DataFrame\n# │ Row │ estimation              │ asset_1    │ asset_2    │ asset_3     │ asset_4     │\n# │     │ String                  │ Float64    │ Float64    │ Float64     │ Float64     │\n# ├─────┼─────────────────────────┼────────────┼────────────┼─────────────┼─────────────┤\n# │ 1   │ True                    │ 0.00216696 │ 0.0092135  │ 0.000226909 │ 0.000938589 │\n# │ 2   │ 2 Scales noise estimate │ 0.0021294  │ 0.00854816 │ 0.000226053 │ 0.000871175 │","category":"page"},{"location":"3_WritingCode/#Estimating-a-covariance-matrix","page":"Writing Code","title":"Estimating a covariance matrix","text":"","category":"section"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"As this is a Monte Carlo we already have the true CovarianceMatrix in the true_covar variable. As we don't have this in applied settings we will disregard this for now and try to estimate it using our data from ts the ts SortedDataFrame:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"assets              = get_assets(ts)\nsimple_estimate     = estimate_covariance(ts, assets, :simple_covariance)\nbnhls_estimate      = estimate_covariance(ts, assets, :bnhls_covariance)\nspectral_estimate   = estimate_covariance(ts, assets, :spectral_covariance)\npreav_estimate      = estimate_covariance(ts, assets, :preaveraged_covariance)\ntwo_scales_estimate = estimate_covariance(ts, assets, :two_scales_covariance)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We may alternatively use the functions corresponding to each method directly. This has the same result:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"bnhls_estimate2     = bnhls_covariance(ts, assets)\nspectral_estimate2  = spectral_covariance(ts, assets)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Now we may be particularly interested in one of the estimates, for instance the bnhls estimate. We can first see if the correlation matrix is valid:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"valid_correlation_matrix(bnhls_estimate)\n# true","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"and fortunately it is. We could also examine the others similarly and see that they all deliver valid correlation matrices. One thing we might try then is to average over all of the more advanced methods and use the result as our correlation matrix estimate. This is easy to achieve by using the combine_covariance_matrices function.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"matrices = [spectral_estimate, preav_estimate, two_scales_estimate, bnhls_estimate]\ncombined_estimate = combine_covariance_matrices(matrices)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Now we can compare how close each of the estimates is to the true correlation matrix. We can do this by examining the mean absolute difference between estimated correlations.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"calculate_mean_abs_distance(true_covar, combined_estimate)\n# (Correlation_error = 0.38723691161754376, Volatility_error = 0.002500211816000063)\ncalculate_mean_abs_distance(true_covar, simple_estimate)\n# (Correlation_error = 0.5321534542489482, Volatility_error = 0.010511960080115556)\ncalculate_mean_abs_distance(true_covar, bnhls_estimate)\n# (Correlation_error = 0.7422120933301078, Volatility_error = 0.006815323622470541)\ncalculate_mean_abs_distance(true_covar, spectral_estimate)\n# (Correlation_error = 0.5227424813357473, Volatility_error = 0.007669889385330695)\ncalculate_mean_abs_distance(true_covar, preav_estimate)\n# (Correlation_error = 0.1840684108352901, Volatility_error = 0.0022421828719004925)\ncalculate_mean_abs_distance(true_covar, two_scales_estimate)\n# (Correlation_error = 0.38238270061443486, Volatility_error = 0.0022421828719004925)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We can see that in this particular case the correlation matrix calculated with preaveraging performed the best.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Now examining the data we can see that we have some assets that trade more frequently than the others.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"ticks_per_asset(ts)\n# Dict{Symbol, Int64} with 4 entries:\n#   :asset_4 => 3454\n#   :asset_3 => 3242\n#   :asset_2 => 1340\n#   :asset_1 => 1964","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"While we have 3454 price updates for asset_4 we only have 1340 for asset_2. Potentially we could improve the bnhls estimate if we use a blocking and regularisation technique (Hautsch, Kyj and Oomen  2012).","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We can start this by first making a DataFrame detailing what assets should be in what block. We will generate a new block if the minimum number of ticks of a new block has 20% more ticks than the minimum of the previous:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"new_block_threshold = 1.2\nblocking_frame = put_assets_into_blocks_by_trading_frequency(\n                        ts, new_block_threshold, :bnhls_covariance)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"This blocking_frame is a regular DataFrame with six columns where each row represents a different estimation. The order of the rows is the order of estimations (so the results of later estimations may overwrite earlier ones). The first column is named :assets and has the type Set{Symbol} which represents the assets in each estimation. The second column contains a symbol representing the function that will be used in the estimation of that block. The third column has the name :optional_parameters and is of type NamedTuple that can provide optional parameters to the covariance function in the second column. Every covariance estimation has a function signature with two common arguments before the semicolon (For a SortedDataFrame and a vector of symbols representing what assets to use). There can also be a number of named optional arguments which can be sourced from a NamedTuple. The blockwise_estimation function then estimates a block with the line","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"blocking_frame[i,:f](ts, collect(blocking_frame[i,:assets]);\n                     blocking_frame[i,:optional_parameters]... )","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Thus a user can insert a named tuple containing whatever optional parameters are used by the function.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"The fourth, fifth and sixth columns contains the number of assets in the block, the mean number of ticks in the block and the mean time per tick. These do not do anything in the subsequent blockwise_estimation function but can be used to alter the dataframe. Now in the current case we may decide to estimate the block containing all assets using the spectral_covariance method.","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"one_asset_row = findall(blocking_frame[:,:number_of_assets] .== 4)\nblocking_frame[one_asset_row, :f] = :spectral_covariance","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"We can now estimate the blockwise estimated CovarianceMatrix as:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"block_estimate = blockwise_estimation(ts, blocking_frame)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"After a blockwise estimation the result may often not be PSD. So we could regularise at this point:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"reg_block_estimate = regularise(block_estimate , ts, :nearest_correlation_matrix)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Finally we might seek to use one of our estimated CovarianceMatrixs to calculate an actual covariance matrix over some interval. This can be done with the code:","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"covariance_interval = 1000\ncovar = covariance(combined_estimate, covariance_interval)","category":"page"},{"location":"3_WritingCode/","page":"Writing Code","title":"Writing Code","text":"Note that the time units of the covariance_interval here should be the same units as the CovarianceMatrix struct's volatility which are the same units as the time dimension in the SortedDataFrame that is used to estimate the CovarianceMatrix.","category":"page"},{"location":"2_data_structures/#Data-Structures","page":"Data Structures","title":"Data Structures","text":"","category":"section"},{"location":"2_data_structures/#Main-Structs","page":"Data Structures","title":"Main Structs","text":"","category":"section"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"HighFrequencyCovariance has two main structs. The first is CovarianceMatrix which is:","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"mutable struct CovarianceMatrix{R<:Real}\n    correlation::Hermitian{R}\n    volatility::Array{R,1}\n    labels::Array{Symbol,1}\nend","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"A CovarianceMatrix struct thus contains three elements. A correlation matrix, a volatility vector and a vector that labels each row/column of the correlation matrix and each row of the volatility vector. Note that an actual covariance matrix is not stored but can be calculated over some interval with the function:","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"covariance(cm::CovarianceMatrix, duration::Real)","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"The second main struct is a SortedDataFrame which is:","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"struct SortedDataFrame\n    df::DataFrame\n    time::Symbol\n    grouping::Symbol\n    value::Symbol\n    groupingrows::Dict{Symbol,Array{Int64,1}}\nend","category":"page"},{"location":"2_data_structures/","page":"Data Structures","title":"Data Structures","text":"This presorts a dataframe by time and adds in an index (groupingrows) for each asset. Together these measures allow the covariance estimation functions to run faster as they can efficiently access the data. The other struct elements are the labels of the columns of interest in the dataframe.","category":"page"},{"location":"1_algorithms/#Algorithms","page":"Algorithms","title":"Algorithms","text":"","category":"section"},{"location":"1_algorithms/#Volatility","page":"Algorithms","title":"Volatility","text":"","category":"section"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"There are two builtin algorithms that purely estimate volatility. These are:","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"simple_volatility this estimates the volatility for each stock given a grid of sampling times. If a grid of sampling times is not input then one is estimated optimally (using a formula suggested by Zhang, Mykland & Aït-Sahalia 2005).\ntwo_scales_volatility This estimates volatility over two different timescales. One short duration (so alot of the measured variation will be from microstructure noise) and one longer duration (so little of the measured variation is from microstructure noise). Then it combines the two estimates to get an estimate of volatility and also of microstructure noise.","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"These two functions can be called directly or through the estimate_volatility function. In this function the method can be specified as either :simple_volatility or :two_scales_volatility.","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"In addition it is generally possible to infer volatility from the covariance matrix estimates. Given a covariance matrix over some interval it is possible to extract the variance of each stock's price and then determine the volatility from that. In most cases when one of the following covariance estimation function is use it is this measure of volatility that is put into the CovarianceMatrix struct.","category":"page"},{"location":"1_algorithms/#Covariance","page":"Algorithms","title":"Covariance","text":"","category":"section"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"There are five algorithms for estimating covariances.","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"The simple_covariance function estimates a covariance matrix in the basic way using a given timegrid. Users can input their own timegrid, their own interval spacing that will be used to make a timegrid or they can choose to use refresh times (which will likely be biased and so is not recommended). If the user does not do this then by default the spacing will be the average (across assets) optimal spacing that is calculated in the simple_volatility function.\nThe preaveraged_covariance function. This first preaverages price updates over certain intervals and then estimates the correlations using the averaged series. As a result of averaging the microstructure noise is reduced and the correlations are more accurate as a result. As the volatilities of preaveraged returns are artificially low we use two scales volatility estimates for volatility in this case (Christensen, Podolskij and Vetter 2013).\nThe two_scales_covariance function. This calculates volatilities using the two_scales_volatility estimator. It then calculated pairwise correlations by comparing the two scales volatility of different linear combinations of the two assets (Ait-Sahalia, Fan and Xiu 2010).\nThe spectral_covariance function - The spectral local method of moments technique  (Bibinger, Hautsch, Malec, and Reiss 2014) starts by breaking the trading period into equally sized subintervals. Given each subinterval we  compute a spectral statistic matrix by using a weighted sum of the returns within that interval. We calculate these weights by means of an orthogonal sine function with some spectral frequency j. Then we gather many different spectral statistic matrices by doing this repeatedly with different spectral frequencies. Our estimate of the covariance matrix is then calculated as the average of these spectral statistics.\nThe bnhls_covariance function - The multivariate realised kernel (Barndorff-Nielsen, Hansen, Lunde, and Shephard 2008 - sometimes called the BNHLS method after the authors) is an algorithm that is designed to provide consistent PSD covariance estimates despite settings where there is microstructure noise (that may not be independent of the underlying price process) and asyncronously traded assets. It is a refinement of an earlier algorithm, the univariate realised kernel estimator, which is faster converging but relies an assumption of independence between microstructure noise and the underlying price process.","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"These five functions can be called directly or through the estimate_covariance function. In this function the method can be specified as :simple_covariance, :preaveraged_covariance, :two_scales_covariance, :spectral_covariance or :bnhls_covariance.","category":"page"},{"location":"1_algorithms/#Regularisation","page":"Algorithms","title":"Regularisation","text":"","category":"section"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"There are four inbuilt regularisation algorithms, identity_regularisation, eigenvalue_clean, nearest_psd_matrix and nearest_correlation_matrix. The first three of these can be applied to either the covariance matrix or to the correlation matrix while the fourth can only be applied to the correlation matrix. If input as a regularisation method to a covariance estimation function, these methods can regularise a covariance matrix before it is split into a correlation matrix and volatilities. It can also be applied purely to the resultant correlation matrix. These regularisation techniques can also be applied directly to a CovarianceMatrix struct either on the correlation matrix or covariance matrix (in which case a covariance matrix is constructed, regularised and then split into a correlation matrix and volatilities that are then placed in a CovarianceMatrix struct).","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"The regularisation techniques are:","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"identity_regularisation -  This regularises a covariance (or correlation) by averaging it with an identity matrix of the same dimensions (Ledoit and Wolf 2001).\neigenvalue_clean - This splits a covariance (or correlation) matrix into its eigenvalue decomposition. Then the distribution of eigenvalues that would be expected if it were a random matrix is computed. Any eigenvalues that are sufficiently small that they could have resulted from a random matrix are averaged together which shrinks their impact while the covariance matrix is still psd (Laloux, Cizeau, Bouchaud and Potters 1999).\nnearest_psd_matrix - This maps an estimated matrix to the nearest psd matrix (Higham 2002).\nnearest_correlation_matrix - This maps an estimated correlation matrix to the nearest psd matrix. And then the nearest unit diagonal (with offdiagonals less than one in absolute value) matrix. Then the nearest psd matrix and so on until it converges. The result is the nearest valid correlation matrix.","category":"page"},{"location":"1_algorithms/","page":"Algorithms","title":"Algorithms","text":"These four functions can be called directly or through the regularise function. In this function the method can be specified as :identity_regularisation, :eigenvalue_clean, :nearest_psd_matrix or :nearest_correlation_matrix.","category":"page"},{"location":"9_references/#References","page":"References","title":"References","text":"","category":"section"},{"location":"9_references/","page":"References","title":"References","text":"Ait-Sahalia Y, Fan J, Xiu D (2010). \"High-Frequency Covariance Estimates With Noisy and Asynchronous Financial Data.\" Journal of the American Statistical Association, 105(492), 1504–1517. doi:10.1198/jasa.2010.tm10163.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Barndorff-Nielsen OE, Hansen PR, Lunde A, Shephard N (2011). \"Multivariate realised kernels: consistent positive semi-definite estimators of the covariation of equity prices with noise and non-synchronous trading.\" Journal of Econometrics, 162(2), 149–169. doi:10.1016/j.jeconom.2010.07.009.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Baumann S, Klymak, M. (2021) \"HighFrequencyCovariance: A Julia Package for Estimating Covariance Matrices Using High Frequency Financial Data.\" SSRN paper 3786912 available at  https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3786912","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Bibinger M, Hautsch N, Malec P, Reiss M (2014). \"Estimating the quadratic covariation matrix from noisy observations: Local method of moments and efficiency.\" The Annals of Statistics, 42(4), 1312–1346. doi:10.1214/14-AOS1224.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Christensen K, Podolskij M, Vetter M (2013). \"On covariation estimation for multivariate continuous Itô semimartingales with noise in non-synchronous observation schemes.\" Journal of Multivariate Analysis, 120, 59–84. doi:10.1016/j.jmva.2013.05.002.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Eps T (1979). \"Comovements in stock prices in the very short run.\" Journal of the American Statistical Association, 74, 291–296. doi:10.1080/01621459.1979.10482508.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Hautsch N, Kyj LM, Oomen RCA (2012). \"A blocking and regularization approach to high-dimensional realized covariance estimation.\" Journal of Applied Econometrics, 27(4), 625–645. doi:10.1002/jae.1218.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Higham NJ (2002). \"Computing the nearest correlation matrix - a problem from finance.\" IMA Journal of Numerical Analysis, 22, 329–343. doi:10.1002/nla.258.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Laloux L, Cizeau P, Bouchaud JP, Potters M (1999). \"Noise Dressing of Financial Correlation Matrices.\" Physical Review Letters, 83(7), 1467–1470. ISSN 1079-7114. doi:10.1103/physrevlett.83.1467.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Ledoit O, Wolf M (2001). \"A well-conditioned estimator for large-dimensional covariance matrices.\" Journal of Multivariate Analysis, 88(2), 365–411. doi:10.1016/S0047-259X(03)00096-4.","category":"page"},{"location":"9_references/","page":"References","title":"References","text":"Zhang L, Mykland PA, Aït-Sahalia Y (2005). \"A Tale of Two Time Scales: Determining Integrated Volatility with Noisy High-Frequency Data.\" Journal of the American Statistical Association, 100(472), 1394–1411. ISSN 01621459. doi:10.1198/016214505000000169.","category":"page"},{"location":"#HighFrequencyCovariance","page":"Introduction","title":"HighFrequencyCovariance","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"This package estimates covariance matrix using high frequency data.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"This task is more complicated than normal covariance estimation due to several features of high frequency financial data:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Assets are traded nonsyncronously. For instance we get an updated GOOG price at 14:28:00 and then get an updated price for MSFT only at 14:28:04. Ignoring the asynchronisity with which we get price updates can downwards bias correlations (Eps 1979).\nPrice updates typically contain some \"microstructure noise\" which reflects frictions in the market rather than the longterm correlations between assets.\nThe microstruture noise can often not be iid but can exhibit serial correlation.\nOften more advanced techniques that adjust for the above issues are not guaranteed to return a PSD covariance matrix. So we need to regularise.\nAssets may be traded over different intervals. For instance in calculating the correlation between JP Morgan and Credit Suisse we might have some days where Credit Suisse does  trade in Zurich but due to thanksgiving JP Morgan is not being traded in New York. So we might need to assemble a covariance matrix where the pairwise covariances/correlations come from slightly different intervals. This can lead to a resultant matrix that is not positive semi definite regardless of the estimation method.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"HighFrequencyCovariance contains 2 volatility estimators, 5 covariance estimators, 4 regularisation techniques and a number of convenience functions that are intended to overcome these issues and produce reliable correlation, volatility and covariance estimates given high frequency financial data.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"A paper (Baumann & Klymak 2021) briefly outlining each technique is accessible. This paper also contains references to the original econometrics papers for users that seek a more detailed understanding.  The paper also contains a Monte Carlo analysis of the accuracy and time complexity of each algorithm. This documentation will not replicate all of that content and will instead focus on the practical details on how to write code to use this package.","category":"page"},{"location":"types/","page":"Types","title":"Types","text":"CurrentModule = HighFrequencyCovariance","category":"page"},{"location":"types/#Types","page":"Types","title":"Types","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"Pages = [\"types.md\"]","category":"page"},{"location":"types/#Type-hierarchy-design","page":"Types","title":"Type hierarchy design","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"SortedDataFrame struct wraps a DataFrame (from the DataFrames package). In the constructor function for the DataFrame we presort the data and create a mapping dict so that it is fast to subset the DataFrame by the group.","category":"page"},{"location":"types/","page":"Types","title":"Types","text":"CovarianceMatrix. This stores three elements. A Hermitian correlation matrix, a vector of volatilities and a vector of labels. The order of the labels matches the order of the assets in the volatility vector and correlation matrix.","category":"page"},{"location":"types/#Types-specification","page":"Types","title":"Types specification","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"SortedDataFrame\nCovarianceMatrix","category":"page"},{"location":"types/#HighFrequencyCovariance.SortedDataFrame","page":"Types","title":"HighFrequencyCovariance.SortedDataFrame","text":"SortedDataFrame(df::DataFrame, time::Symbol = :Time, grouping::Symbol = :Name, value::Symbol = :Value)\n\nThis struct wraps a DataFrame. In the constructor function for the dataframe we presort the data and create a mapping dict so that it is fast to subset the DataFrame by the group.\n\nTo construct pass in the dataframe, name of time column, name of grouping column and name of value column to the constructor.\n\n\n\n\n\n","category":"type"},{"location":"types/#HighFrequencyCovariance.CovarianceMatrix","page":"Types","title":"HighFrequencyCovariance.CovarianceMatrix","text":"This stores three elements. A Hermitian correlation matrix, a vector of volatilities and a vector of labels. The order of the labels matches the order of the assets in the volatility vector and correlation matrix.\n\n\n\n\n\n","category":"type"}]
}
